{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateusduarte-max/Projetos_Python/blob/main/11_Reputacao_Nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGUR49VdpF5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d79eb5b-cfaf-4d08-bb4e-23ac09ec3128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting workadays\n",
            "  Downloading workadays-2022.8.8-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from workadays) (2.8.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from workadays) (1.15.0)\n",
            "Installing collected packages: workadays\n",
            "Successfully installed workadays-2022.8.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "querys_reputacao.ipynb:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n"
          ]
        }
      ],
      "source": [
        "#!pip install --upgrade openpyxl # atualização pacote excel\n",
        "!pip install workadays # modulo para calcular data prometida e data limite de postagem\n",
        "!pip install unidecode # modulo para retirar caracteres especiais\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import datetime\n",
        "from workadays import workdays as wd\n",
        "import numpy as np\n",
        "import unidecode\n",
        "\n",
        "# Bibliotecas Google Golab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "# Importar biblioteca biqquery\n",
        "from google.cloud import bigquery\n",
        "# Bibliotecas Google Sheet\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "# Montar Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Classe Dados\n",
        "!cp /content/drive/MyDrive/Colab_Notebooks/pacotes_modulos/modulos_colab.py /content\n",
        "from modulos_colab import dados\n",
        "# Chaves e tokens\n",
        "!cp /content/drive/MyDrive/Colab_Notebooks/Autenticacoes/chaves_tokens.py /content\n",
        "%run chaves_tokens.py\n",
        "# Querys reputação\n",
        "!cp /content/drive/MyDrive/Colab_Notebooks/querys/querys_reputacao.ipynb /content\n",
        "%run querys_reputacao.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculo Reputação"
      ],
      "metadata": {
        "id": "E9UFaPhOp-3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta  bigQuery reclamações formais\n",
        "reclamacoes_formais = dados.consulta_bigquery(projeto_gcp_1, query_reclamacoes_formais)\n",
        "# Tratativa base\n",
        "reclamacoes_formais.rename(columns={'seller_id_pedido':'LOJISTA'}, inplace=True)\n",
        "reclamacoes_formais['LOJISTA'] = reclamacoes_formais['LOJISTA'].str.strip().str.lower().str.split('/',1).str[0].str.split('-', 1).str[0]\n",
        "reclamacoes_formais_resumo = pd.pivot_table(reclamacoes_formais, index='LOJISTA', values='pedido', aggfunc='nunique', margins=True)\n",
        "reclamacoes_formais_resumo.rename(columns={'pedido':'Qtd_Reclamacoes_Formais'}, inplace=True)\n",
        "\n",
        "# Grava na tabela (Google Drive)\n",
        "dados.grava_tabela_drive('Base_reclamacoes_formais', 'Página1',reclamacoes_formais)\n",
        "\n",
        "\n",
        "#reclamacoes_formais = busca_tabela_drive('Base_reclamacoes_formais')\n",
        "#reclamacoes_formais.rename(columns={'seller_id_pedido':'LOJISTA'}, inplace=True)\n",
        "#reclamacoes_formais['LOJISTA'] = reclamacoes_formais['LOJISTA'].str.strip().str.lower().str.split('/',1).str[0].str.split('-', 1).str[0]\n",
        "#reclamacoes_formais_resumo = pd.pivot_table(reclamacoes_formais, index='LOJISTA', values='AtendimentoCodigo', aggfunc='count', margins=True)\n",
        "#reclamacoes_formais_resumo.rename(columns={'AtendimentoCodigo':'Qtd_Reclamacoes_Formais'}, inplace=True)\n",
        "\n",
        "######################  ############################################################################################################\n",
        "# Consulta pedidos bigQuery nets\n",
        "base_pedidos = dados.consulta_bigquery(projeto_gcp_1, query_pedidos_nets)\n",
        "\n",
        "###################### Retirada pedidos com checkin - Base original #########################################################################################\n",
        "#pedidos['COD_PEDIDO'] = pedidos['COD_PEDIDO'].astype(str)\n",
        "#pedidos_checkin = pd.merge(pedidos,pedidos_ckeckin, how='left', on='COD_PEDIDO' )\n",
        "#base_pedidos = pedidos_checkin.query('STATUS_checkin!=\"Finalizado\"')\n",
        "###################### Tratativa base original ##############################################################################################################\n",
        "\n",
        "# Formatar campos de data\n",
        "base_pedidos['DATA_APROV'] = base_pedidos['DATA_APROV'].astype(object)\n",
        "base_pedidos['DATA_APROV'] = pd.to_datetime(base_pedidos['DATA_APROV'])\n",
        "base_pedidos['mes_data_aprovacao'] = base_pedidos['DATA_APROV'].dt.month\n",
        "base_pedidos['DIAS_PRAZO'] = base_pedidos['DIAS_PRAZO'].replace('',0)\n",
        "base_pedidos['DATA_PEDIDO'] = base_pedidos['DATA_PEDIDO'].astype(object)\n",
        "base_pedidos['DATA_PEDIDO'] = pd.to_datetime(base_pedidos['DATA_PEDIDO'])\n",
        "base_pedidos['MES_DATA_PEDIDO'] = base_pedidos['DATA_PEDIDO'].dt.month\n",
        "base_pedidos['DATA_ENTREGA'] = pd.to_datetime(base_pedidos['DATA_ENTREGA'])\n",
        "base_pedidos['DATA_DESPACHO'] = pd.to_datetime(base_pedidos['DATA_DESPACHO'])\n",
        "base_pedidos['Hoje'] = datetime.datetime.today().strftime('%Y-%m-%d')\n",
        "base_pedidos['Hoje'] = pd.to_datetime(base_pedidos['Hoje'], format='%Y-%m-%d')\n",
        "#Formatar colunas Lojista e Id seller\n",
        "base_pedidos['STATUS'] = base_pedidos['STATUS'].str.strip()\n",
        "base_pedidos['LOJISTA'] = base_pedidos['LOJISTA'].str.lower()\n",
        "base_pedidos['ID_SELLER'] = base_pedidos['ID_SELLER'].str.strip()\n",
        "base_pedidos['ID_SELLER'] = base_pedidos['ID_SELLER'].astype(str)\n",
        "\n",
        "# Data Prometida\n",
        "base_pedidos['DATA_PROMETIDA'] = pd.to_datetime(base_pedidos['DATA_PROMETIDA'])\n",
        "base_pedidos['mes_data_prometida'] = base_pedidos['DATA_PROMETIDA'].dt.month\n",
        "\n",
        "# Sellers blocado\n",
        "sellers_blocado = ['13514',\n",
        "                  '7968',\n",
        "                  '9321',\n",
        "                  '3328',\n",
        "                  '1483',\n",
        "                  '4761',\n",
        "                  '6749',\n",
        "                  '13590',\n",
        "                  '12806',\n",
        "                  '4901',\n",
        "                  '5382',\n",
        "                  '2281',\n",
        "                  '12114',\n",
        "                  '3468',\n",
        "                  '10641',\n",
        "                  '4282',\n",
        "                  '3441',\n",
        "                  '5021',\n",
        "                  '5941',\n",
        "                  '581',\n",
        "                  '9963',\n",
        "                  '13268',\n",
        "                  '4188',\n",
        "                  '7930',\n",
        "                  '12666',\n",
        "                  '12739',\n",
        "                  '4764',\n",
        "                  '7861',\n",
        "                  '12865',\n",
        "                  '11932',\n",
        "                  '7644',\n",
        "                  '12089',\n",
        "                  '3464',\n",
        "                  '6721',\n",
        "                  '13201',\n",
        "                  '2082',\n",
        "                  '3421',\n",
        "                  '12814',\n",
        "                  '12799',\n",
        "                  '5601',\n",
        "                  '7934',\n",
        "                  '12855',\n",
        "                  '11956',\n",
        "                  '12130',\n",
        "                  '9501',\n",
        "                  '4230',\n",
        "                  '12844',\n",
        "                  '14699',\n",
        "                  '581',\n",
        "                  '14673',\n",
        "                  '14630',\n",
        "                  '13268',\n",
        "                  '14278',\n",
        "                  '14587',\n",
        "                  '14887',\n",
        "                  '14550',\n",
        "                  '14970',\n",
        "                  '15182',\n",
        "                  '14897',\n",
        "                  '15057',\n",
        "                  '14967',\n",
        "                  '1356',\n",
        "                  '3131',\n",
        "                  '15237',\n",
        "                  '15173',\n",
        "                  '13002',\n",
        "                  '15244',\n",
        "                  '15116',\n",
        "                  '15574',\n",
        "                  '15510',\n",
        "                  '15269',\n",
        "                  '14697',\n",
        "                  '3385',\n",
        "                  '15812',\n",
        "                  '16164',\n",
        "                  '15971',\n",
        "                  '16243',\n",
        "                  '15206',\n",
        "                  '16273',\n",
        "                  '16116',\n",
        "                  '14468',\n",
        "                  '16755',\n",
        "                  '17115',\n",
        "                  '14755',\n",
        "                  '17008',\n",
        "                  '16151',\n",
        "                  '17274',\n",
        "                  '17471']\n",
        "#Função para coluna blocado\n",
        "def seller_blocado(base_pedidos):\n",
        "  if (base_pedidos['ID_SELLER'] in sellers_blocado):\n",
        "    return 'sim'\n",
        "  else:\n",
        "    return 'não' \n",
        "# Coluna Blocado\n",
        "base_pedidos['Blocado'] = base_pedidos.apply(seller_blocado, axis=1)\n",
        "\n",
        "################################################################# Base pedidos  ###################################################################\n",
        "base_pedidos_mes_v1 = base_pedidos.query('DATA_PROMETIDA<=\"{}\"'.format(hoje)).drop_duplicates()\n",
        "\n",
        "base_pedidos_mes_v1['validacao_data'] = base_pedidos_mes_v1['DATA_APROV'].fillna('sem_data')\n",
        "\n",
        "def excluir_pedidos_cancelados(base_pedidos_mes_v1):\n",
        "    if base_pedidos_mes_v1['STATUS'] == 'CANCELADO' and base_pedidos_mes_v1['validacao_data']=='sem_data':\n",
        "        return 'excluir'\n",
        "    else:\n",
        "        return 'ok'\n",
        "\n",
        "base_pedidos_mes_v1['validacao_pedidos'] = base_pedidos_mes_v1.apply(excluir_pedidos_cancelados, axis=1)\n",
        "\n",
        "base_pedidos_mes = base_pedidos_mes_v1.query('validacao_pedidos!=\"excluir\"')\n",
        "\n",
        "base_pedidos_mes.drop(columns=[\"validacao_pedidos\", \"validacao_data\"], inplace=True)\n",
        "\n",
        "# Total pedidos\n",
        "base_seller_lojista = base_pedidos_mes[['ID_SELLER','LOJISTA', 'Tipo_Envio']]\n",
        "base_tt_pedidos = pd.DataFrame(pd.pivot_table(base_pedidos_mes, index=['ID_SELLER','LOJISTA','Tipo_Envio'], columns='STATUS', values='COD_PEDIDO', aggfunc='count',margins=True, margins_name='TT_Pedidos')).fillna(0)\n",
        "\n",
        "################################################################## Pedidos Entregues ################################################################\n",
        "# Pedidos Entregues\n",
        "base_pedidos_entregues = base_pedidos_mes.query('STATUS==\"ENTREGUE\"')\n",
        "def analise_pedidos(base_pedidos_entregues):\n",
        "  if base_pedidos_entregues['DATA_ENTREGA'] <= base_pedidos_entregues['DATA_PROMETIDA']:\n",
        "    return 'entregue_dentro_prazo'\n",
        "  else:\n",
        "    return 'entregue_fora_prazo'\n",
        "base_pedidos_entregues['status_entrega'] = base_pedidos_entregues.apply(analise_pedidos, axis=1)\n",
        "resumo_base_pedidos_entregues = pd.DataFrame(pd.pivot_table(base_pedidos_entregues, index=['ID_SELLER','LOJISTA'], columns='status_entrega', values='COD_PEDIDO', aggfunc='count').fillna(0))\n",
        "##################################################################3 Concatenação 1 ######################################################################\n",
        "\n",
        "concatenacao_0 = pd.merge(base_seller_lojista,base_tt_pedidos, how='left', on=['ID_SELLER','LOJISTA','Tipo_Envio']).fillna(0).drop_duplicates()\n",
        "concatenacao_1 = pd.merge(concatenacao_0,resumo_base_pedidos_entregues, how='left' , on=['ID_SELLER','LOJISTA']).drop_duplicates()\n",
        "\n",
        "##################################################################### Pedidos Despachados ################################################################\n",
        "\n",
        "# Base pedidos despachado\n",
        "base_pedidos_despachado = base_pedidos_mes.query('STATUS==[\"DESPACHADO\",\"ENTREGUE\"] & DATA_DESPACHO!=\"\"').drop_duplicates()\n",
        "# Função limite de postagem\n",
        "def data_limite_postagem(base_pedidos_despachado):\n",
        "  if base_pedidos_despachado['Tipo_Envio'] == 'NSE':\n",
        "    return wd.workdays(base_pedidos_despachado['DATA_APROV'], base_pedidos_despachado['dias_prazo_nse'], country='BR')\n",
        "  elif base_pedidos_despachado['Tipo_Envio'] == 'Não' and base_pedidos_despachado['Blocado'] == 'não': \n",
        "    return wd.workdays(base_pedidos_despachado['DATA_APROV'], 2, country='BR')\n",
        "  elif base_pedidos_despachado['Tipo_Envio'] == 'Não' and base_pedidos_despachado['Blocado'] == 'sim': \n",
        "    return wd.workdays(base_pedidos_despachado['DATA_APROV'], 5, country='BR')  \n",
        "  else:\n",
        "      return \"\"  \n",
        "base_pedidos_despachado['DATA_LIMITE_POSTAGEM'] = base_pedidos_despachado.apply(data_limite_postagem, axis=1)\n",
        "\n",
        "# Função análise postagem\n",
        "def analise_postagem(base_pedidos_despachado):\n",
        "  if base_pedidos_despachado['DATA_DESPACHO'] <= base_pedidos_despachado['DATA_LIMITE_POSTAGEM']:\n",
        "    return 'postagem_dentro_prazo'\n",
        "  else:\n",
        "    return 'postagem_fora_prazo'\n",
        "base_pedidos_despachado['status_postagem'] = base_pedidos_despachado.apply(analise_postagem, axis=1)\n",
        "resumo_base_pedidos_despachado = pd.DataFrame(pd.pivot_table(base_pedidos_despachado, index=['ID_SELLER','LOJISTA'], columns='status_postagem', values='COD_PEDIDO', aggfunc='count').fillna(0))\n",
        "\n",
        "##################################################################3 Concatenação 2 ####################################################################\n",
        "\n",
        "concatenacao_2 = pd.merge(concatenacao_1,resumo_base_pedidos_despachado, how='left' , on=['ID_SELLER','LOJISTA']).drop_duplicates()\n",
        "\n",
        "##################################################################### Pedidos Pendentes ################################################################\n",
        "# Base Pedidos Faturados\n",
        "base_pedidos_faturado = base_pedidos_mes.query('STATUS==\"FATURADO\"')\n",
        "# Função limite postagem\n",
        "def data_limite_postagem(base_pedidos_faturado):\n",
        "  if base_pedidos_faturado['Tipo_Envio'] == 'NSE':\n",
        "    return wd.workdays(base_pedidos_faturado['DATA_APROV'], base_pedidos_faturado['dias_prazo_nse'], country='BR')\n",
        "  elif base_pedidos_faturado['Tipo_Envio'] == 'Não' and base_pedidos_faturado['Blocado'] == 'não': \n",
        "    return wd.workdays(base_pedidos_faturado['DATA_APROV'], 2, country='BR')\n",
        "  elif base_pedidos_faturado['Tipo_Envio'] == 'Não' and base_pedidos_faturado['Blocado'] == 'sim': \n",
        "    return wd.workdays(base_pedidos_faturado['DATA_APROV'], 5, country='BR')\n",
        "  else:\n",
        "      return \"\"    \n",
        "base_pedidos_faturado['DATA_LIMITE_POSTAGEM'] = base_pedidos_faturado.apply(data_limite_postagem, axis=1)\n",
        "\n",
        "# Base Pedidos Pronto para faturar\n",
        "base_pedidos_pronto_faturar = base_pedidos_mes.query('STATUS==\"PRONTO PARA FATURAR\" & DATA_APROV!=\"\"')\n",
        "base_pedidos_pronto_faturar['dias_prazo_nse'] = base_pedidos_pronto_faturar['dias_prazo_nse'].astype(int)\n",
        "# Função limite postagem\n",
        "def data_limite_postagem(base_pedidos_pronto_faturar):\n",
        "  if base_pedidos_pronto_faturar['Tipo_Envio'] == 'NSE':\n",
        "    return wd.workdays(base_pedidos_pronto_faturar['DATA_APROV'], base_pedidos_pronto_faturar['dias_prazo_nse'], country='BR')\n",
        "  elif  base_pedidos_pronto_faturar['Tipo_Envio'] == 'Não' and base_pedidos_pronto_faturar['Blocado'] == 'não': \n",
        "    return wd.workdays(base_pedidos_pronto_faturar['DATA_APROV'], 2, country='BR')\n",
        "  elif  base_pedidos_pronto_faturar['Tipo_Envio'] == 'Não' and base_pedidos_pronto_faturar['Blocado'] == 'sim': \n",
        "    return wd.workdays(base_pedidos_pronto_faturar['DATA_APROV'], 5, country='BR')  \n",
        "  else:\n",
        "      return \"\"  \n",
        "base_pedidos_pronto_faturar['DATA_LIMITE_POSTAGEM'] = base_pedidos_pronto_faturar.apply(data_limite_postagem, axis=1)\n",
        "\n",
        "# Concatenação bases\n",
        "pedidos_pendentes = pd.concat([base_pedidos_faturado, base_pedidos_pronto_faturar]).drop_duplicates()\n",
        "\n",
        "\n",
        "# Coluna ontem\n",
        "pedidos_pendentes['Ontem'] = pedidos_pendentes['Hoje'] - datetime.timedelta(days = 1)\n",
        "# Coluna Pedidos Atrasados\n",
        "def pedidos_em_atraso(pedidos_pendentes):\n",
        "  if pedidos_pendentes['DATA_PROMETIDA'] <= pedidos_pendentes['Ontem']: \n",
        "    return 'Pedido_Atrasado'\n",
        "  else:\n",
        "    return ''\n",
        "pedidos_pendentes['Pedidos_Atrasados'] =  pedidos_pendentes.apply(pedidos_em_atraso, axis=1)   \n",
        "\n",
        "# Coluna Expedição  Atrasada\n",
        "def expedicao_em_atraso(pedidos_pendentes):\n",
        "  if pedidos_pendentes['DATA_LIMITE_POSTAGEM'] <= pedidos_pendentes['Ontem']: \n",
        "    return 'Expedicao_Atrasada'\n",
        "  else:\n",
        "    return ''\n",
        "pedidos_pendentes['Pedidos_Expedicao_Atrasada'] =  pedidos_pendentes.apply(expedicao_em_atraso, axis=1)\n",
        "\n",
        "base1 = pedidos_pendentes.query('Pedidos_Atrasados==\"Pedido_Atrasado\"').drop_duplicates(subset=['ID_SELLER', 'COD_PEDIDO_LOJA'])\n",
        "resumo_base1 = pd.pivot_table(base1, index='ID_SELLER', values=['Pedidos_Atrasados'], aggfunc='count')\n",
        "base2 = pedidos_pendentes.query('Pedidos_Expedicao_Atrasada==\"Expedicao_Atrasada\"').drop_duplicates(subset=['ID_SELLER', 'COD_PEDIDO_LOJA'])\n",
        "resumo_base2 = pd.pivot_table(base2, index='ID_SELLER', values=['Pedidos_Expedicao_Atrasada'], aggfunc='count')\n",
        "\n",
        "######################################################################### Dados KA Nets ######################################################################################\n",
        "dados_ka = dados.consulta_bigquery(projeto_gcp_1, query_ka)\n",
        "dados_ka.rename(columns={'group_owner':'Assistido', 'code':'ID_SELLER'}, inplace=True)\n",
        "dados_ka['Assistido'] = dados_ka['Assistido'].str.replace('Não Assistido', 'Não_Assistido')\n",
        "# Função sellers ka\n",
        "def sellers_ka(dados_ka):\n",
        "  if dados_ka['Assistido'] == 'Assistido':\n",
        "    return \"Key Account\"\n",
        "  else:\n",
        "    return 'Long Tail'\n",
        "dados_ka['Key Account?']  = dados_ka.apply(sellers_ka, axis=True)\n",
        "dados_ka_final = dados_ka[['ID_SELLER', 'Key Account?']]\n",
        "dados_ka_final['ID_SELLER'] = dados_ka_final['ID_SELLER'].apply(str)\n",
        "dados_ka_final['ID_SELLER'] = dados_ka_final['ID_SELLER'].str.strip()\n",
        "\n",
        "##################################################################3 Concatenação 3 e 4 ####################################################################################\n",
        "\n",
        "#concatenacao_3 = pd.merge(concatenacao_2, base_seller_lojista, how='left', on=['ID_SELLER','LOJISTA']).drop_duplicates()\n",
        "concatenacao_4 = pd.merge(concatenacao_2, dados_ka_final, how='left', on=['ID_SELLER']).drop_duplicates()\n",
        "######################################################################### Dados CR e Nps #################################################################################\n",
        "\n",
        "dados_cr_nps = dados.consulta_bigquery(projeto_gcp_1, query_cr_nps)\n",
        "\n",
        "#dados_cr_nps['CR_Seller'] = round((dados_cr_nps['CR_Seller']*100),2)\n",
        "dados_cr_nps['CR_Seller'] = pd.to_numeric(dados_cr_nps['CR_Seller']).fillna(0)\n",
        "dados_cr_nps['NPS_Seller'] = pd.to_numeric(dados_cr_nps['NPS_Seller']).fillna(0)\n",
        "dados_cr_nps['LOJISTA'] = dados_cr_nps['Seller_id'].str.lower()\n",
        "dinamica_cr_nps = dados_cr_nps[['LOJISTA', 'CR_Seller', 'NPS_Seller']].drop_duplicates(subset='LOJISTA')\n",
        "\n",
        "##################################################################3 Concatenação 6 ####################################################################################\n",
        "\n",
        "concatenacao_5 = pd.merge(concatenacao_4, dinamica_cr_nps , how='left', on=['LOJISTA']).drop_duplicates()\n",
        "######################################################################### Base Hubsales #################################################################################\n",
        "# Import base\n",
        "#'/content/drive/MyDrive/Ciclo Pedidos Nets Novo/sellers Hubsales - BF.xlsx'\n",
        "base_husales = pd.read_excel(base_hubsales, usecols=['Id Seller', \n",
        "                                                    'Nome Loja', \n",
        "                                                    'Hubsales?']).fillna(0)\n",
        "# Ajustes colunas\n",
        "base_husales.rename(columns={'Id Seller':'ID_SELLER', 'Nome Loja':'LOJISTA'}, inplace=True)\n",
        "base_husales['ID_SELLER'] = base_husales['ID_SELLER'].apply(int).apply(str)\n",
        "base_husales['LOJISTA'] = base_husales['LOJISTA'].str.lower()\n",
        "base_husales_final = base_husales[['ID_SELLER', 'Hubsales?']]\n",
        "\n",
        "##################################################################3 Concatenação 7 ####################################################################################\n",
        "concatenacao_6 = pd.merge(concatenacao_5, base_husales_final , how='left', on=['ID_SELLER']).drop_duplicates()\n",
        "concatenacao_6['Hubsales?'] = concatenacao_6['Hubsales?'].fillna('Não')\n",
        "\n",
        "######################################################################### Concatenação 8 e 9 #################################################################################\n",
        "\n",
        "concatencao_7 = pd.merge(concatenacao_6,resumo_base1, how='left', on='ID_SELLER').drop_duplicates()\n",
        "concatencao_7['Pedidos_Atrasados'] = concatencao_7['Pedidos_Atrasados'].fillna(0)\n",
        "concatencao_8 = pd.merge(concatencao_7,resumo_base2, how='left', on='ID_SELLER').drop_duplicates()\n",
        "concatencao_8['Pedidos_Expedicao_Atrasada'] = concatencao_8['Pedidos_Expedicao_Atrasada'].fillna(0)\n",
        "\n",
        "######################################################################### Base GMV ###################################################################################################\n",
        "base_pedidos_mes_gmv = pd.pivot_table(base_pedidos_mes, index='ID_SELLER', values='VLR', aggfunc='sum')\n",
        "base_pedidos_mes_gmv.rename(columns={'VLR':'GMV'}, inplace=True)\n",
        "\n",
        "######################################################################### Concatenação 10 ###########################################################################################\n",
        "\n",
        "concatencao_9 = pd.merge(concatencao_8, base_pedidos_mes_gmv, how='left', on='ID_SELLER').drop_duplicates()\n",
        "concatencao_9['GMV'] = concatencao_9['GMV'].astype(float)\n",
        "concatencao_9['GMV'] = round(concatencao_9['GMV'],2)\n",
        "\n",
        "######################################################################### Concatenação 11 ###########################################################################################\n",
        "\n",
        "concatenacao_10 = pd.merge(concatencao_9, reclamacoes_formais_resumo , how='left', on=['LOJISTA']).drop_duplicates()\n",
        "concatenacao_10['Qtd_Reclamacoes_Formais'] = concatenacao_10['Qtd_Reclamacoes_Formais'].fillna(0)\n",
        "\n",
        "######################################################################### Indicador de reputação #####################################################################################\n",
        "concatenacao_10['% Entrega'] = round((concatenacao_10['entregue_dentro_prazo']/concatenacao_10['TT_Pedidos'])*100,2).fillna(0)\n",
        "concatenacao_10['% Postagem'] = round((concatenacao_10['postagem_dentro_prazo']/concatenacao_10['TT_Pedidos'])*100,2).fillna(0)\n",
        "concatenacao_10['% Cancelados'] = round((concatenacao_10['CANCELADO']/concatenacao_10['TT_Pedidos'])*100,2).fillna(0)\n",
        "concatenacao_10['% Reclamação'] = round((concatenacao_10['Qtd_Reclamacoes_Formais']/concatenacao_10['TT_Pedidos'])*100,2).fillna(0)\n",
        "\n",
        "# Classificação  regua entrega, despacho, cancelados, reclamação e nps\n",
        "def regra_entrega(concatenacao_10):\n",
        "  if concatenacao_10['% Entrega'] >= 0.00 and concatenacao_10['% Entrega'] <= 84.99:\n",
        "    return 1\n",
        "  elif concatenacao_10['% Entrega'] >= 85.00 and concatenacao_10['% Entrega'] <= 88.99:\n",
        "    return 2\n",
        "  elif concatenacao_10['% Entrega'] >= 89.00 and concatenacao_10['% Entrega'] <= 92.99:\n",
        "    return 3\n",
        "  elif concatenacao_10['% Entrega'] >= 93.00 and concatenacao_10['% Entrega'] <= 94.99:\n",
        "    return 4\n",
        "  elif concatenacao_10['% Entrega'] >= 95.00:\n",
        "    return 5\n",
        "concatenacao_10['reg_entrega'] = concatenacao_10.apply(regra_entrega, axis=1)\n",
        "\n",
        "\n",
        "def regra_despacho(concatenacao_10):\n",
        "  if concatenacao_10['% Postagem'] >= 0.00 and concatenacao_10['% Postagem'] <= 84.99:\n",
        "    return 1\n",
        "  elif concatenacao_10['% Postagem'] >= 85.00 and concatenacao_10['% Postagem'] <= 88.99:\n",
        "    return 2\n",
        "  elif concatenacao_10['% Postagem'] >= 89.00 and concatenacao_10['% Postagem'] <= 92.99:\n",
        "    return 3\n",
        "  elif concatenacao_10['% Postagem'] >= 93.00 and concatenacao_10['% Postagem'] <= 94.99:\n",
        "    return 4\n",
        "  elif concatenacao_10['% Postagem'] >= 95.00:\n",
        "    return 5\n",
        "concatenacao_10['reg_Postagem'] = concatenacao_10.apply(regra_despacho, axis=1)\n",
        "\n",
        "\n",
        "def regra_cancelados(concatenacao_10):\n",
        "  if concatenacao_10['% Cancelados'] <= 2.00:\n",
        "    return 5\n",
        "  elif concatenacao_10['% Cancelados'] >= 2.01 and concatenacao_10['% Cancelados'] <= 3.00:\n",
        "    return 4\n",
        "  elif concatenacao_10['% Cancelados'] >= 3.01 and concatenacao_10['% Cancelados'] <= 4.0:\n",
        "    return 3\n",
        "  elif concatenacao_10['% Cancelados'] >= 4.01 and concatenacao_10['% Cancelados'] <= 5.00:\n",
        "    return 2\n",
        "  elif concatenacao_10['% Cancelados'] >= 5.01:\n",
        "    return 1\n",
        "concatenacao_10['reg_Cancelados'] = concatenacao_10.apply(regra_cancelados, axis=1)\n",
        "\n",
        "\n",
        "def regra_reclamacao(concatenacao_10):\n",
        "  if concatenacao_10['% Reclamação'] <= 1.00:\n",
        "    return 5\n",
        "  elif concatenacao_10['% Reclamação'] >= 1.01 and concatenacao_10['% Reclamação'] <= 2.50:\n",
        "    return 4\n",
        "  elif concatenacao_10['% Reclamação'] >= 2.51 and concatenacao_10['% Reclamação'] <= 3.50:\n",
        "    return 3\n",
        "  elif concatenacao_10['% Reclamação'] >= 3.51 and concatenacao_10['% Reclamação'] <= 4.00:\n",
        "    return 2\n",
        "  elif concatenacao_10['% Reclamação'] >= 4.01:\n",
        "    return 1\n",
        "concatenacao_10['reg_Reclamação'] = concatenacao_10.apply(regra_reclamacao, axis=1)\n",
        "\n",
        "\n",
        "def regra_nps(concatenacao_10):\n",
        "  if concatenacao_10['NPS_Seller'] <= 64.99 :\n",
        "    return 1\n",
        "  elif concatenacao_10['NPS_Seller'] >= 65.00 and concatenacao_10['NPS_Seller'] <= 67.99:\n",
        "    return 2\n",
        "  elif concatenacao_10['NPS_Seller'] >= 68.00 and concatenacao_10['NPS_Seller'] <= 70.00:\n",
        "    return 3\n",
        "  elif concatenacao_10['NPS_Seller'] >= 70.01 and concatenacao_10['NPS_Seller'] <= 74.99:\n",
        "    return 4\n",
        "  elif concatenacao_10['NPS_Seller'] >= 75.00:\n",
        "    return 5\n",
        "concatenacao_10['reg_nps'] = concatenacao_10.apply(regra_nps, axis=1)\n",
        "\n",
        "\n",
        "def regra_cr(concatenacao_10):\n",
        "  if concatenacao_10['CR_Seller'] >= 0.301 :\n",
        "    return 1\n",
        "  elif concatenacao_10['CR_Seller'] >= 0.201 and concatenacao_10['CR_Seller'] <= 0.300:\n",
        "    return 2\n",
        "  elif concatenacao_10['CR_Seller'] >= 0.151 and concatenacao_10['CR_Seller'] <= 0.200:\n",
        "    return 3\n",
        "  elif concatenacao_10['CR_Seller'] >= 0.101 and concatenacao_10['CR_Seller'] <= 0.150:\n",
        "    return 4\n",
        "  elif concatenacao_10['CR_Seller'] <= 0.100:\n",
        "    return 5\n",
        "concatenacao_10['reg_cr'] = concatenacao_10.apply(regra_cr, axis=1)\n",
        "\n",
        "\n",
        "# Indicador da reputação\n",
        "def funcao_reputacao(concatenacao_10):\n",
        "  if concatenacao_10['Tipo_Envio'] == 'Não':\n",
        "    return round((concatenacao_10['reg_nps']/5*1.45)+(concatenacao_10['reg_entrega']/5*1.50)+(concatenacao_10['reg_cr']/5*0.50)+(concatenacao_10['reg_Reclamação']/5*0.35)+(concatenacao_10['reg_Cancelados']/5*1.20),2)\n",
        "  elif concatenacao_10['Tipo_Envio'] == 'NSE':\n",
        "    return round((concatenacao_10['reg_nps']/5*1.45)+(concatenacao_10['reg_Postagem']/5*1.50)+(concatenacao_10['reg_cr']/5*0.50)+(concatenacao_10['reg_Reclamação']/5*0.35)+(concatenacao_10['reg_Cancelados']/5*1.20),2)\n",
        "concatenacao_10['Indicador_Reputacao'] = concatenacao_10.apply(funcao_reputacao, axis=1)\n",
        "\n",
        "############################################################################## Ingestão BigQuery ########################################################################################\n",
        "\n",
        "# Tabela Dash - BigQuery\n",
        "# renomear colunas para BigQuery\n",
        "\n",
        "concatenacao_10.rename(columns={'PRONTO PARA FATURAR':'Pronto_para_faturar',\n",
        "                                'Key Account?':'Key_Account',\n",
        "                                'Hubsales?':'Hubsales',\n",
        "                                'Ns_Entregas?':'Ns_Entregas',\n",
        "                                '% Entrega':'P_Entrega',\n",
        "                                '% Postagem':'P_Postagem',\n",
        "                                '% Cancelados':'P_Cancelados',\n",
        "                                '% Reclamação':'P_Reclamacao',\n",
        "                                'reg_Reclamação':'reg_Reclamacao'}, inplace=True)\n",
        "\n",
        "concatenacao_12 = concatenacao_10.query('ID_SELLER!=\"TT_Pedidos\"')\n",
        "# Gravar tabela\n",
        "concatenacao_12.to_gbq(destination_table='marketplace_analytics.dados_reputacao_nets',project_id=projeto_gcp_1, if_exists='replace')\n",
        "# Gravar tabela\n",
        "dados.grava_tabela_drive('Tb_pedidos_pendentes_reputacao','Página1',pedidos_pendentes)\n",
        "# Gravar tabela\n",
        "pedidos_cancelados = base_pedidos_mes.query('STATUS==\"CANCELADO\"')\n",
        "dados.grava_tabela_drive('Tb_pedidos_cancelados', 'Página1',pedidos_cancelados)\n",
        "\n",
        "print(\"Reputação Atualizada!!\")\n"
      ],
      "metadata": {
        "id": "vwuCCfEdsUwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72991275-079a-400c-a2c4-2c537b7468f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:178: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/workadays/workdays.py:38: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
            "  while dt_aux in holidays or is_weekend(dt_aux):\n",
            "/usr/local/lib/python3.7/dist-packages/workadays/workdays.py:52: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
            "  if dt_aux in holidays:\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:199: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:227: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:227: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:231: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:242: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:242: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:283: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:284: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n",
            "1it [01:17, 77.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reputação Atualizada!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l7m3hjFkXzNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comunicação - Massivo\n",
        "concatenacao_13 = concatenacao_12.query('TT_Pedidos>=10')\n",
        "comunicacao = concatenacao_13.copy()\n",
        "\n",
        "def concat_comunicacao(comunicacao):\n",
        "    if comunicacao['Tipo_Envio']=='Não':\n",
        "        return ('Reputação:'+ str(comunicacao['Indicador_Reputacao'])+\" =  \"+ \n",
        "                'Entrega:'+ str(comunicacao['P_Entrega'])+\"   \"+\n",
        "                'NPS:'+ str(comunicacao['NPS_Seller'])+\"   \"+\n",
        "                'Cancelamento:'+ str(comunicacao['P_Cancelados'])+\"   \"+\n",
        "                'CR:'+ str(comunicacao['CR_Seller'])+\"   \"+\n",
        "                'Reclamação:'+ str(comunicacao['P_Reclamacao']))\n",
        "    elif comunicacao['Tipo_Envio']=='NSE':\n",
        "        return ('Reputação:'+ str(comunicacao['Indicador_Reputacao'])+\" =  \"+ \n",
        "                'Postagem:'+ str(comunicacao['P_Postagem'])+\"   \"+\n",
        "                'NPS:'+ str(comunicacao['NPS_Seller'])+\"   \"+\n",
        "                'Cancelamento:'+ str(comunicacao['P_Cancelados'])+\"   \"+\n",
        "                'CR:'+ str(comunicacao['CR_Seller'])+\"   \"+\n",
        "                'Reclamação:'+ str(comunicacao['P_Reclamacao']))\n",
        "      \n",
        "\n",
        "comunicacao['Concat_comunicacao'] = comunicacao.apply(concat_comunicacao, axis=1)\n",
        "comunicacao_v2 = comunicacao[['ID_SELLER', 'LOJISTA', 'Indicador_Reputacao', 'Concat_comunicacao']]\n",
        "dados.grava_tabela_drive('comunicacao_export', 'Página1',comunicacao_v2)\n",
        "\n",
        "print(\" Tabela Comunicação Atualizada!\")\n"
      ],
      "metadata": {
        "id": "fYKaRnoH9CHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edcde584-9805-4b28-ac15-50924f96fec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tabela Comunicação Atualizada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Atualizar acompanhamento Gerencial\n",
        "concatenacao_13['Data_Atualizacao'] = datetime.datetime.now().strftime('%Y-%m-%d')\n",
        "acompanhamento = concatenacao_13[['ID_SELLER',\n",
        "                                  'LOJISTA', \n",
        "                                  'CANCELADO',\n",
        "                                  'DESPACHADO',\n",
        "                                  'ENTREGUE',\n",
        "                                  'FATURADO',\n",
        "                                  'Pronto_para_faturar',\n",
        "                                  'TT_Pedidos',\n",
        "                                  'entregue_dentro_prazo',\n",
        "                                  'entregue_fora_prazo',\n",
        "                                  'postagem_dentro_prazo',\n",
        "                                  'postagem_fora_prazo',\n",
        "                                  'Key_Account',\n",
        "                                  'Tipo_Envio',\n",
        "                                  'CR_Seller',\n",
        "                                  'NPS_Seller',\n",
        "                                  'Hubsales',\n",
        "                                  'Pedidos_Atrasados',\n",
        "                                  'Pedidos_Expedicao_Atrasada',\n",
        "                                  'GMV',\n",
        "                                  'Qtd_Reclamacoes_Formais',\n",
        "                                  'P_Entrega',\n",
        "                                  'P_Postagem',\n",
        "                                  'P_Cancelados',\n",
        "                                  'P_Reclamacao',\n",
        "                                  'reg_entrega',\n",
        "                                  'reg_Postagem',\n",
        "                                  'reg_Cancelados',\n",
        "                                  'reg_Reclamacao',\n",
        "                                  'reg_nps',\n",
        "                                  'reg_cr',\n",
        "                                  'Indicador_Reputacao',\n",
        "                                  'Data_Atualizacao']] \n",
        "\n",
        "def linhas():\n",
        "    arquivo = gc.open('Acompanhamento_Gerencial_Reputação_nets')\n",
        "    # abrir planilha 'aba'\n",
        "    aba = arquivo.worksheet('Página1')\n",
        "    # colocar a aba dentro de um data_frame\n",
        "    df = pd.DataFrame(aba.get_all_records())\n",
        "    #Visualização\n",
        "    numero = df['LOJISTA'].count()+2\n",
        "    n = int(numero)\n",
        "    return n\n",
        "\n",
        "def input_drive():\n",
        "  #Abrir planilha e primeira aba\n",
        "    pagina = gc.open('Acompanhamento_Gerencial_Reputação_nets').sheet1\n",
        "  # Limpar base\n",
        "  #pagina.clear()\n",
        "  # Importar dataframe na planilha\n",
        "    return set_with_dataframe(pagina, acompanhamento, row=linhas(), include_column_header=False)\n",
        "input_drive()\n",
        "\n",
        "\n",
        "print(\"Acompanhamento Gerencial - Reputação Atualizada!!\")"
      ],
      "metadata": {
        "id": "zAVIRGrbcaVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3521f624-8418-44a6-b2ab-c118bb05ea5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acompanhamento Gerencial - Reputação Atualizada!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MPikIit7Xro7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}