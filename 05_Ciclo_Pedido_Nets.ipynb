{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateusduarte-max/Projetos_Python/blob/main/05_Ciclo_Pedido_Nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXGZP36MbRJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2bafa4-8490-44c7-d946-2b0515badb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting workadays\n",
            "  Downloading workadays-2021.12.18-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from workadays) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from workadays) (2.8.2)\n",
            "Installing collected packages: workadays\n",
            "Successfully installed workadays-2021.12.18\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 29.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#!pip install --upgrade openpyxl # atualização pacote excel\n",
        "!pip install workadays # modulo para calcular data prometida e data limite de postagem\n",
        "!pip install unidecode # modulo para retirar caracteres especiais\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import datetime\n",
        "from workadays import workdays as wd\n",
        "import numpy as np\n",
        "import unidecode\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.cloud import bigquery\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Modulos \n",
        "!cp /content/drive/MyDrive/Colab_Notebooks/pacotes_modulos/modulos_colab.py /content\n",
        "!cp /content/drive/MyDrive/Colab_Notebooks/Autenticacoes/chaves_tokens.py /content\n",
        "%run chaves_tokens.py\n",
        "# Importar biblioteca biqquery\n",
        "from modulos_colab import dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oguz7Em_oxMb"
      },
      "source": [
        "Ciclo Pedido Nets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variaveis Globais\n",
        "data_base = (datetime.datetime.now() - datetime.timedelta(45)).strftime('%Y-%m-%d')\n",
        "\n",
        "# Consulta reclamações formais\n",
        "\n",
        "reclamacoes_formais = dados.consulta_bigquery(projeto_gcp_1,\"\"\"SELECT W101.* ,\n",
        "                                                                        cast(a.PEDS_DAT_CAD as date) as Data_captado,cast(a.PEDS_DAT_FAT as date) as Data_faturado,cast(a.PEDS_DAT_PRZINI as date) as Data_Prazo_Entrega, tetrix.* except(code),a.PEDS_COD ,a.PEDS_EXT_COD,\n",
        "\n",
        "                                                                        CASE \n",
        "                                                                            WHEN UPPER(CAST(a.PEDS_COD as string)) like '%N%'  THEN 'Pedido Reverso'\n",
        "                                                                            WHEN UPPER(CAST(a.PEDS_EXT_COD  as string)) like '%N%' then 'Pedido Reverso'\n",
        "                                                                            WHEN UPPER(CAST(a.PEDS_COD as string)) like '%Z%'  THEN 'Pedido Reverso' \n",
        "                                                                            WHEN UPPER(CAST(a.PEDS_EXT_COD  as string)) like '%Z%' then 'Pedido Reverso'     \n",
        "                                                                        ELSE 'Não é Reverso' end as Pedido_Reverso, \n",
        "\n",
        "                                                                        CASE\n",
        "                                                                        WHEN W101.LojaWebNome in ('ALLIANZ PARQUE','B2b Coorporativo','B2b Netshoes','CLUBE NETSHOES','Csu','CSU Passaporte Opte+','DIGI NETSHOES','Dotz','Freedom - Chapecoense','Freedom - Freelace','Freedom - Kappa','Freedom - Loja Cruzeiro','Freedom - Loja Internacional','Freedom - Loja Nba','Freedom - Netshoes','Freedom - Palmeiras','Freedom - Santos','Freedom - Sao Paulo','Freedom - Shoptimao','Freedom - Vasco','Func Netshoes','ITAU IUPP NETSHOES','Livelo','LOJA GAP','LOJA NFL','LOJA WSL','Ltm','MARKUP NETSHOES','Multiplus','Nba','NETSHOES','NIKE FUNCIONARIOS','NS2 - AMZ (Amazon)','NS2 - B2W','NS2 - CRF (Carrefour)','NS2 - MGL (Magazine Luiza)','NS2 - MLI (Mercado Livre)','NS2 - VVJ (ViaVarejo)','Shoestock','Shoestock Loja Fisica','SMILES NETSHOES','TUDO AZUL - NETSHOES','B2W','CRUZEIRO','Csu Banescard','Csu Banestes','Csu Banpará','Csu Banrisul','Csu Electrolux','Csu Pernambucanas','Csu Porto Seguro','Csu Vivo','Loja Do Itaú','MULTIPLUS NETSHOES MKTP','NS2 - BCP','PALMEIRAS','SANTOS','SÃO PAULO MANIA','SHOPTIMAO','Vasco') THEN 'Nets'\n",
        "                                                                        WHEN W101.LojaWebNome in ('CSU - SHOPPING ZATTINI','Csu Banrisul - Zattini','Csu Passaporte Opte+ - Zattini','Freedom - Zattini','Livelo Zattini','Ltm Zattini','MARKUP ZATTINI','Multiplus Zattini','SHOPFACIL ZATTINI','Smiles Zattini','TUDO AZUL - ZATTINI','ZATTINI','Csu Banescard - Zattini','Csu Banestes - Zattini','Csu Banpará - Zattini','Csu Electrolux - Zattini','Csu Pernambucanas - Zattini','Csu Porto Seguro - Zattini','Csu Vivo - Zattini','MULTIPLUS ZATTINI MKTP') THEN 'Zattini'\n",
        "                                                                        ELSE W101.LojaWebNome END as Depara_Grupo,\n",
        "\n",
        "                                                                        CASE \n",
        "                                                                        WHEN W101.LojaWebNome in ('ALLIANZ PARQUE') THEN 'ALLIANZ PARQUE'\n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Chapecoense') THEN 'Chapecoense' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Loja Cruzeiro','CRUZEIRO') THEN 'Cruzeiro' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Freelace') THEN 'Freelace' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Func Netshoes') THEN 'Func Netshoes' \n",
        "                                                                        WHEN W101.LojaWebNome in ('LOJA GAP') THEN 'GAP' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Loja Internacional') THEN 'Internacional' \n",
        "                                                                        WHEN W101.LojaWebNome in ('ITAU IUPP NETSHOES','Loja Do Itaú') THEN 'IUPP' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Kappa') THEN 'Kappa' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Loja Nba','Nba') THEN 'Nba' \n",
        "                                                                        WHEN W101.LojaWebNome in ('LOJA NFL') THEN 'NFL' \n",
        "                                                                        WHEN W101.LojaWebNome in ('NIKE FUNCIONARIOS') THEN 'NIKE FUNCIONARIOS' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Palmeiras','PALMEIRAS') THEN 'Palmeiras' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Santos','SANTOS') THEN 'Santos' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Sao Paulo','SÃO PAULO MANIA') THEN 'Sao Paulo' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Shoestock Loja Fisica','Shoestock') THEN 'Shoestock' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Shoptimao','SHOPTIMAO') THEN 'Shoptimao' \n",
        "                                                                        WHEN W101.LojaWebNome in ('Freedom - Vasco','Vasco') THEN 'Vasco' \n",
        "                                                                        WHEN W101.LojaWebNome in ('LOJA WSL') THEN 'WSL' \n",
        "                                                                        WHEN W101.LojaWebNome in ('CSU - SHOPPING ZATTINI','Csu Banrisul - Zattini','Csu Passaporte Opte+ - Zattini','Freedom - Zattini','Livelo Zattini','Ltm Zattini','MARKUP ZATTINI','Multiplus Zattini','SHOPFACIL ZATTINI','Smiles Zattini','TUDO AZUL - ZATTINI','ZATTINI','Csu Banescard - Zattini','Csu Banestes - Zattini','Csu Banpará - Zattini','Csu Electrolux - Zattini','Csu Pernambucanas - Zattini','Csu Porto Seguro - Zattini','Csu Vivo - Zattini','MULTIPLUS ZATTINI MKTP') \n",
        "                                                                        THEN 'Zattini' \n",
        "                                                                        WHEN LojaWebNome in ('B2b Coorporativo','B2b Netshoes','CLUBE NETSHOES','Csu','CSU Passaporte Opte+','DIGI NETSHOES','Dotz','Freedom - Chapecoense','Freedom - Freelace','Freedom - Kappa','Freedom - Loja Cruzeiro','Freedom - Loja Internacional','Freedom - Loja Nba','Freedom - Netshoes','Freedom - Palmeiras','Freedom - Santos','Freedom - Sao Paulo','Freedom - Shoptimao','Freedom - Vasco','Func Netshoes','ITAU IUPP NETSHOES','Livelo','LOJA GAP','LOJA NFL','LOJA WSL','Ltm','MARKUP NETSHOES','Multiplus','Nba','NETSHOES','NIKE FUNCIONARIOS','NS2 - AMZ (Amazon)','NS2 - B2W','NS2 - CRF (Carrefour)','NS2 - MGL (Magazine Luiza)','NS2 - MLI (Mercado Livre)','NS2 - VVJ (ViaVarejo)','Shoestock','Shoestock Loja Fisica','SMILES NETSHOES','TUDO AZUL - NETSHOES','B2W','CRUZEIRO','Csu Banescard','Csu Banestes','Csu Banpará','Csu Banrisul','Csu Electrolux','Csu Pernambucanas','Csu Porto Seguro','Csu Vivo','Loja Do Itaú','MULTIPLUS NETSHOES MKTP','NS2 - BCP') THEN 'Nets' \n",
        "                                                                        ELSE LojaWebNome END as Depara_Loja,\n",
        "\n",
        "                                                                        CASE \n",
        "                                                                        WHEN lower(W101.Transportadora) in ('air cargo recife ltda') THEN 'Air Cargo LTDA'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('atlas transportes') THEN 'Atlas Transprote'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('carriers logistica e transportes ltda me') THEN 'Carriers Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('empresa brasileira de correios e telegrafos') THEN 'Correios'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('dgt logistica e transportes ltda.','dgt logística e transportes ltda.') THEN 'DGT Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('dialogo logistica inteligente ltda epp','diálogo logística inteligente ltda epp') THEN 'Díalogo Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('direct express logistica integrada s/a','direct express logística integrada s/a') THEN 'Direct Express'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('dsl negocios e servicos especiais ltda','dsl negócios e serviços especiais ltda') THEN 'DSL Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('ecolivery courieros me') THEN 'Ecolivery Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('expresso jundiai logistica e transporte ltda') THEN 'Expresso Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in (\"faro's - transportes comercio importac?o e exportac?o ltda\",\"faro's - transportes comércio importação e exportação ltda\") THEN 'Faro Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('fast courier servicos ltda','fast courier serviços ltda') THEN 'Fast Courier LTDA'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('gfl logistica ltda') THEN 'GFL Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('inside the time transportes ltda.') THEN 'Inside the Time LTDA'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('jadlog logistica ltda','jadlog logistica ltda.') THEN 'Jadlog'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('jamef transportes') THEN 'Jamef Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('l4b logistica ltda') THEN 'L4B Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('lmtrans logistica em transportes ltda') THEN 'LMTrans Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('logbee','expressa- logbee') THEN 'Logbee'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('magalog') THEN 'Magalog'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('nhl logistica inteligente ltda') THEN 'NHL Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('on time express logistica e transportes ltda') THEN 'On time'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('rapid?o cometa logistica e transporte s/a','rapidão cometa logistica e transporte s/a','rapidão cometa logística e transporte s/a') THEN 'Rapidão Cometa'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('rbs - zero hora editora jornalistica s.a.') THEN 'RBS Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('sem transportadora') THEN 'Sem Transportadora'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('sequoia logistica e transportes sa','sequoia logística e transportes sa') THEN 'Sequoia Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('total express') THEN 'Total Express'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('transfolha transporte e distribuic?o ltda','transfolha transporte e distribuicão ltda','transfolha transporte e distribuição ltda') THEN 'Transfolha'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('transportadora netshoes','netshoes - frota propria') THEN 'Transportadora Netshoes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('air express fermac assessoria e consultoria em logistica e transporte ltda') THEN 'Air Express Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('braspress transportes urgentes ltda') THEN 'Braspress Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('cajumar transportes ltda') THEN 'Cajumar Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('ctl logistica me') THEN 'CTL Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('emerson rodrigo violin me') THEN 'Emerson Rodrigo Violin ME'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('gdr express network transportes ltda') THEN 'GDR Express'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('gps motos') THEN 'GPS Motos'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('irmãos silveira transportes em geral ltda') THEN 'Silveira Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('leonardo zenko pires de carvalho - me') THEN 'LEONARDO ZENKO PIRES DE CARVALHO - ME'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('lmtrans logística em transportes ltda') THEN 'LMTRANS Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('movmov tecnologia da informacao ltda') THEN 'MovMov Tecnologias'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('nfn ferreira logistica em transportes de carga ltda') THEN 'NFN Logística'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('pacifico log transportes') THEN 'Pacífico Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('ramos transportes') THEN 'Ramos Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('ss reversa e projetos customizados ltda - epp') THEN 'SS Reversa'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('tex log') THEN 'Tex Log'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('transp. padrao mkp') THEN 'Transportadora Padrão MKP'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('transportadora route ltda') THEN 'Route Transportadora'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('tsv transportes rapidos') THEN 'TSV Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('transportadora shoestock') THEN 'Transportadora Shoestock'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('wf gomes transportes - me') THEN 'WF Transportes'\n",
        "                                                                        WHEN lower(W101.Transportadora) in ('empresa brasileira de transportes') THEN 'Empresa Brasileira de Transportes'\n",
        "                                                                        ELSE lower(W101.Transportadora) end as Depara_Transportadora,\n",
        "\n",
        "                                                                        FROM `maga-bigdata.sac.pc_abacos_sac` AS W101\n",
        "                                                                        LEFT JOIN `maga-bigdata.abacos_nets.aba_tcom_pedsai` as a on a.PEDS_COD = W101.Pedido\n",
        "                                                                        LEFT JOIN (SELECT DISTINCT o.code, ifnull(STRING_AGG(DISTINCT b.name,\"/\" order by b.name),'Pedido_1P') as seller_id_pedido, ifnulL(STRING_AGG(DISTINCT c.distribution_center_name,\"/\" order by c.distribution_center_name),'Sem CD Cadastrado') as cds_pedido,\n",
        "                                                                                MIN(billing_date) as dt_pagamento_menor_pedido,MIN(dispatch_date) as dt_despacho_menor_pedido,MAX(o.sales_channel) as canal_venda\n",
        "                                                                                FROM `maga-bigdata.tetrix.vw_order_sale` as o\n",
        "                                                                                LEFT JOIN `maga-bigdata.tetrix.vw_order_shipping` as a on a.order_id = o.id\n",
        "                                                                                LEFT JOIN `maga-bigdata.tetrix.vw_seller` as b on cast(b.code as string) = a.seller_id\n",
        "                                                                                LEFT JOIN `maga-bigdata.tetrix.vw_shipping_product` as c on c.order_shipping_id = a.id\n",
        "                                                                                GROUP BY 1)as tetrix on tetrix.code = a.PEDS_EXT_COD \n",
        "                                                                        WHERE 1=1\n",
        "                                                                        AND AtendimentoOrigemNome in ('Jurídico Procon','Jurídico Cível')\n",
        "                                                                        AND W101.AtendimentoServicoNome  in ('Reclamações formais')\n",
        "                                                                        AND CAST(AtendimentoDataInicial as date) >= '{}'\"\"\".format(data_base))\n",
        "\n",
        "# Tratativa base\n",
        "reclamacoes_formais.rename(columns={'seller_id_pedido':'LOJISTA'}, inplace=True)\n",
        "reclamacoes_formais['LOJISTA'] = reclamacoes_formais['LOJISTA'].str.strip().str.lower().str.split('/',1).str[0].str.split('-', 1).str[0]\n",
        "reclamacoes_formais_resumo = pd.pivot_table(reclamacoes_formais, index='LOJISTA', values='AtendimentoCodigo', aggfunc='count', margins=True)\n",
        "reclamacoes_formais_resumo.rename(columns={'AtendimentoCodigo':'Qtd_Reclamacoes_Formais'}, inplace=True)\n",
        "\n",
        "# Grava na tabela (Google Drive)\n",
        " \n",
        "#dados.grava_tabela_drive('Base_reclamacoes_formais', reclamacoes_formais)\n",
        "print(\"Bloco executado\")\n",
        "\n",
        "#reclamacoes_formais = busca_tabela_drive('Base_reclamacoes_formais')\n",
        "#reclamacoes_formais.rename(columns={'seller_id_pedido':'LOJISTA'}, inplace=True)\n",
        "#reclamacoes_formais['LOJISTA'] = reclamacoes_formais['LOJISTA'].str.strip().str.lower().str.split('/',1).str[0].str.split('-', 1).str[0]\n",
        "#reclamacoes_formais_resumo = pd.pivot_table(reclamacoes_formais, index='LOJISTA', values='AtendimentoCodigo', aggfunc='count', margins=True)\n",
        "#reclamacoes_formais_resumo.rename(columns={'AtendimentoCodigo':'Qtd_Reclamacoes_Formais'}, inplace=True)\n",
        "\n",
        "#########################################################################################################################################################################################\n",
        "\n",
        "# Dados pedidos com checkin\n",
        "'''pedidos_ckeckin = dados.consulta_bigquery(projeto_gcp_1,\"\"\"SELECT DISTINCT\n",
        "                                                            A.PEDS_COD COD_PEDIDO,\n",
        "                                                            --A.PEDS_EXT_COD PEDIDO_EXTERNO,\n",
        "                                                            --B.TROD_COD CODIGO_DA_TROCA,\n",
        "                                                            B.TROD_STR_STA STATUS_checkin,\n",
        "                                                            --C.ITET_DAT_PROENT DATA_CHECKIN\n",
        "                                                            FROM `maga-bigdata.abacos_nets.aba_tcom_pedsai` A\n",
        "                                                            INNER JOIN `maga-bigdata.abacos_nets.aba_ttrd_trodev` B ON A.CLIF_COD = B.CLIF_COD\n",
        "                                                            --INNER JOIN `maga-bigdata.abacos_nets.aba_ttrd_itetrd` C ON B.TROD_COD = C.TROD_COD\n",
        "                                                            --WHERE A.PEDS_COD IN ('XXX')\n",
        "                                                            WHERE B.TROD_STR_STA in ('Finalizado', 'Aberto')\t\n",
        "                                                                --AND PEDS_VAL_PED = ITET_VAL_PRETOT\n",
        "                                                                --ITET_DAT_PROENT IS NOT NULL\n",
        "                                                                --ITET_DAT_PROENT >='2019-01-01'\n",
        "                                                                --AND B.TROD_DAT_PRAPRO >= '2021-09-01'\n",
        "                                                                --and A.PEDS_COD = 864944870\n",
        "                                                            group by A.PEDS_COD, B.TROD_STR_STA\"\"\")\n",
        "\n",
        "\n",
        "pedidos_ckeckin['COD_PEDIDO'] = pedidos_ckeckin['COD_PEDIDO'].astype(str)'''\n",
        "###################### Consulta pedidos nets bq #######################################################################################################\n",
        "pedidos = dados.consulta_bigquery(projeto_gcp_1,\"\"\"Select distinct\n",
        "                                                    shp.seller_name as LOJISTA,\n",
        "                                                    shp.seller_id as ID_SELLER,\n",
        "                                                    os.code as COD_PEDIDO_LOJA,\n",
        "                                                    osh.delivery_id as COD_PEDIDO,\n",
        "                                                    cast(dispatch_date as date) as DATA_DESPACHO,\n",
        "                                                    cast(delivered_date as date) as DATA_ENTREGA,\n",
        "                                                    cast(os.sale_date as date) as DATA_PEDIDO,\n",
        "                                                    cast(osh.billing_date as date) as DATA_FATURADO,\n",
        "                                                    --cast(payment_confirmation_date as date) as DATA_CONFIR_PGTO,\n",
        "                                                    cast(first_date_payment as date) as DATA_APROV,\n",
        "                                                    cast(expected_delivery_date as date) as DATA_PROMETIDA,\n",
        "                                                    store_code as UNI_NEG,\n",
        "                                                    dead_line_in_days as DIAS_PRAZO,\n",
        "                                                    osh.shipping_status_name as STATUS, \n",
        "                                                    shipping_address_city as MUNICIPIO,\n",
        "                                                    shipping_address_state_code as ESTADO,\n",
        "                                                    ad.postal_code as CEP,\n",
        "                                                    n.Ns_Entregas as Tipo_Envio,\n",
        "                                                    (case when d.default_handling_time is null then 0 else (d.default_handling_time/24) end) as dias_prazo_nse,\n",
        "                                                    --sum((shp.value_placed) + (case when shp.seller_id != '0' then shp.value_freight else 0 end)) as VLR,\n",
        "                                                    --sum(case when osh.billing_date is null then 0 else (shp.value_placed) + (case when shp.seller_id != '0' then osh.freight else 0 end) end) as VLR,\n",
        "                                                    --sum(shp.value_freight) as FRETE,\n",
        "                                                    shp.value_placed as VLR,\n",
        "                                                    shp.value_freight as frete\n",
        "                                                    --ck.Status_checkin\n",
        "                                                FROM `maga-bigdata.netshoes_dw.vw_order_full` os, \n",
        "                                                unnest(os.order_shipping) osh,  unnest(osh.shipping_product) shp, unnest(shipping_status_history) hist\n",
        "                                                left join maga-bigdata.netshoes_dw.vw_order_address_shipping ad on ad.order_id = os.order_id and ad.order_shipping_id = osh.order_shipping_id\n",
        "                                                left join maga-bigdata.marketplace_analytics.sellers_nets_nse as n on n.ID_SELLER = shp.seller_id\n",
        "                                                left join (SELECT\n",
        "                                                                --id,\n",
        "                                                                seller_name,\n",
        "                                                                default_handling_time,\n",
        "                                                                name\n",
        "                                                            FROM\n",
        "                                                                maga-bigdata.maga_onboarding.distribution_center dc\n",
        "                                                            JOIN\n",
        "                                                                maga-bigdata.maga_onboarding.handling_time ht ON ht.id = dc.handling_time_id\n",
        "                                                            JOIN\n",
        "                                                                maga-bigdata.maga_onboarding.origin_address oa ON oa.id = dc.address_id\n",
        "                                                            JOIN\n",
        "                                                                maga-bigdata.maga_onboarding.distribution_center_organizations dco ON dco.distributioncenter_id = dc.id\n",
        "                                                            JOIN\n",
        "                                                                maga-bigdata.maga_onboarding.organization o ON o.id = dco.organization_id\n",
        "                                                                where name='netshoes'\n",
        "                                                                group by seller_name,default_handling_time, name) as d on d.seller_name = shp.seller_id\n",
        "\n",
        "                                                left join (SELECT DISTINCT\n",
        "                                                                    A.PEDS_COD COD_PEDIDO,\n",
        "                                                                    --A.PEDS_EXT_COD PEDIDO_EXTERNO,\n",
        "                                                                    --B.TROD_COD CODIGO_DA_TROCA,\n",
        "                                                                    B.TROD_STR_STA Status_checkin,\n",
        "                                                                    --C.ITET_DAT_PROENT DATA_CHECKIN\n",
        "                                                                    FROM `maga-bigdata.abacos_nets.aba_tcom_pedsai` A\n",
        "                                                                    INNER JOIN `maga-bigdata.abacos_nets.aba_ttrd_trodev` B ON A.CLIF_COD = B.CLIF_COD\n",
        "                                                                    --INNER JOIN `maga-bigdata.abacos_nets.aba_ttrd_itetrd` C ON B.TROD_COD = C.TROD_COD\n",
        "                                                                    --WHERE A.PEDS_COD IN ('XXX')\n",
        "                                                                    WHERE B.TROD_STR_STA in ('Finalizado', 'Aberto')\t\n",
        "                                                                        --AND PEDS_VAL_PED = ITET_VAL_PRETOT\n",
        "                                                                        --ITET_DAT_PROENT IS NOT NULL\n",
        "                                                                        --ITET_DAT_PROENT >='2019-01-01'\n",
        "                                                                        --AND B.TROD_DAT_PRAPRO >= '2021-09-01'\n",
        "                                                                        --and A.PEDS_COD = 864944870\n",
        "                                                                    group by A.PEDS_COD, B.TROD_STR_STA) as ck on cast(ck.COD_PEDIDO as string) = osh.delivery_id             \n",
        "                                                        where\n",
        "                                                        cast(os.sale_date as date) >= '{}'\n",
        "                                                        --EXTRACT(YEAR FROM date(expected_delivery_date)) = 2022\n",
        "                                                        --and EXTRACT(MONTH FROM date(expected_delivery_date)) = 06\n",
        "                                                        --and date(expected_delivery_date) <= current_date() \n",
        "                                                        and os.code not like '%T%'\n",
        "                                                        and shp.source = '3P' \n",
        "                                                        and os.is_ignore_pickup = false\n",
        "                                                        and NOT(os.amount >= 50000 AND osh.status = 12) \n",
        "                                                        and IFNULL(cancel_code,0) <> 100 \n",
        "                                                        and osh.shipping_status_name in ('CANCELADO', 'DESPACHADO', 'ENTREGUE', 'FATURADO', 'PRONTO PARA FATURAR')\n",
        "                                                        and ck.Status_checkin is null\n",
        "                                                        group by \n",
        "                                                        1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20\"\"\".format(data_base))\n",
        "\n",
        "###################### Retirada pedidos com checkin - Base original #########################################################################################\n",
        "#pedidos_checkin = pd.merge(pedidos,pedidos_ckeckin, how='left', on='COD_PEDIDO' )\n",
        "#base_pedidos = pedidos_checkin.query('STATUS_checkin!=[\"Finalizado\",\"Aberto\"]')\n",
        "pedidos['STATUS_checkin'] = ''\n",
        "\n",
        "base_pedidos = pedidos.copy()\n",
        "\n",
        "# Formatar campos de data\n",
        "base_pedidos['DATA_APROV'] = base_pedidos['DATA_APROV'].astype(object)\n",
        "base_pedidos['DATA_APROV'] = pd.to_datetime(base_pedidos['DATA_APROV'])\n",
        "base_pedidos['mes_data_aprovacao'] = base_pedidos['DATA_APROV'].dt.month\n",
        "base_pedidos['DIAS_PRAZO'] = base_pedidos['DIAS_PRAZO'].replace('',0)\n",
        "base_pedidos['DATA_PEDIDO'] = base_pedidos['DATA_PEDIDO'].astype(object)\n",
        "base_pedidos['DATA_PEDIDO'] = pd.to_datetime(base_pedidos['DATA_PEDIDO'])\n",
        "base_pedidos['MES_DATA_PEDIDO'] = base_pedidos['DATA_PEDIDO'].dt.month\n",
        "base_pedidos['DATA_ENTREGA'] = pd.to_datetime(base_pedidos['DATA_ENTREGA'])\n",
        "base_pedidos['DATA_DESPACHO'] = pd.to_datetime(base_pedidos['DATA_DESPACHO'])\n",
        "base_pedidos['Hoje'] = datetime.datetime.today().strftime('%Y-%m-%d')\n",
        "base_pedidos['Hoje'] = pd.to_datetime(base_pedidos['Hoje'], format='%Y-%m-%d')\n",
        "#Formatar colunas Lojista e Id seller\n",
        "base_pedidos['STATUS'] = base_pedidos['STATUS'].str.strip()\n",
        "base_pedidos['LOJISTA'] = base_pedidos['LOJISTA'].str.lower()\n",
        "base_pedidos['ID_SELLER'] = base_pedidos['ID_SELLER'].str.strip()\n",
        "base_pedidos['ID_SELLER'] = base_pedidos['ID_SELLER'].astype(str)\n",
        "\n",
        "base_pedidos['DATA_PROMETIDA'] = pd.to_datetime(base_pedidos['DATA_PROMETIDA'])\n",
        "base_pedidos['mes_data_prometida'] = base_pedidos['DATA_PROMETIDA'].dt.month\n",
        "\n",
        "# Sellers blocado\n",
        "sellers_blocado = ['13514',\n",
        "                  '7968',\n",
        "                  '9321',\n",
        "                  '3328',\n",
        "                  '1483',\n",
        "                  '4761',\n",
        "                  '6749',\n",
        "                  '13590',\n",
        "                  '12806',\n",
        "                  '4901',\n",
        "                  '5382',\n",
        "                  '2281',\n",
        "                  '12114',\n",
        "                  '3468',\n",
        "                  '10641',\n",
        "                  '4282',\n",
        "                  '3441',\n",
        "                  '5021',\n",
        "                  '5941',\n",
        "                  '581',\n",
        "                  '9963',\n",
        "                  '13268',\n",
        "                  '4188',\n",
        "                  '7930',\n",
        "                  '12666',\n",
        "                  '12739',\n",
        "                  '4764',\n",
        "                  '7861',\n",
        "                  '12865',\n",
        "                  '11932',\n",
        "                  '7644',\n",
        "                  '12089',\n",
        "                  '3464',\n",
        "                  '6721',\n",
        "                  '13201',\n",
        "                  '2082',\n",
        "                  '3421',\n",
        "                  '12814',\n",
        "                  '12799',\n",
        "                  '5601',\n",
        "                  '7934',\n",
        "                  '12855',\n",
        "                  '11956',\n",
        "                  '12130',\n",
        "                  '9501',\n",
        "                  '4230',\n",
        "                  '12844',\n",
        "                  '14699',\n",
        "                  '581',\n",
        "                  '14673',\n",
        "                  '14630',\n",
        "                  '13268',\n",
        "                  '14278',\n",
        "                  '14587',\n",
        "                  '14887',\n",
        "                  '14550',\n",
        "                  '14970',\n",
        "                  '15182',\n",
        "                  '14897',\n",
        "                  '15057',\n",
        "                  '14967',\n",
        "                  '1356',\n",
        "                  '3131',\n",
        "                  '15237',\n",
        "                  '15173',\n",
        "                  '13002',\n",
        "                  '15244',\n",
        "                  '15116',\n",
        "                  '15574',\n",
        "                  '15510',\n",
        "                  '15269',\n",
        "                  '14697',\n",
        "                  '3385',\n",
        "                  '15812',\n",
        "                  '16164',\n",
        "                  '15971',\n",
        "                  '16243',\n",
        "                  '15206',\n",
        "                  '16273',\n",
        "                  '16116',\n",
        "                  '14468',\n",
        "                  '16755',\n",
        "                  '17115',\n",
        "                  '14755',\n",
        "                  '17008',\n",
        "                  '16151',\n",
        "                  '17274',\n",
        "                  '17471']\n",
        "#Função para coluna blocado\n",
        "def seller_blocado(base_pedidos):\n",
        "  if (base_pedidos['ID_SELLER'] in sellers_blocado):\n",
        "    return 'sim'\n",
        "  else:\n",
        "    return 'não' \n",
        "# Coluna Blocado\n",
        "base_pedidos['Blocado'] = base_pedidos.apply(seller_blocado, axis=1)\n",
        "\n",
        "################################################################# Base pedidos acumulado ##########################################################\n",
        "\n",
        "# Base Pedidos acumulada sem cancelamento\n",
        "base_pedidos_mes = base_pedidos.query('STATUS!=\"CANCELADO\"').drop_duplicates()\n",
        "\n",
        "# Total pedidos\n",
        "base_seller_lojista = base_pedidos_mes[['ID_SELLER','LOJISTA', 'Tipo_Envio']]\n",
        "base_tt_pedidos = pd.DataFrame(pd.pivot_table(base_pedidos_mes, index=['ID_SELLER','LOJISTA', 'Tipo_Envio'], columns='STATUS', values='COD_PEDIDO', aggfunc='count',margins=True, margins_name='TT_Pedidos')).fillna(0)\n",
        "\n",
        "################################################################## Pedidos Entregues ################################################################\n",
        "# Pedidos Entregues\n",
        "base_pedidos_entregues = base_pedidos_mes.query('STATUS==\"ENTREGUE\"')\n",
        "base_pedidos_entregues['Media_Entregas_Dias'] = (base_pedidos_entregues['DATA_ENTREGA']-base_pedidos_entregues['DATA_PROMETIDA'])\n",
        "base_pedidos_entregues['Media_Entregas_Dias'] = base_pedidos_entregues['Media_Entregas_Dias'].dt.days\n",
        "def analise_pedidos(base_pedidos_entregues):\n",
        "  if base_pedidos_entregues['DATA_ENTREGA'] <= base_pedidos_entregues['DATA_PROMETIDA']:\n",
        "    return 'entregue_dentro_prazo'\n",
        "  else:\n",
        "    return 'entregue_fora_prazo'\n",
        "base_pedidos_entregues['status_entrega'] = base_pedidos_entregues.apply(analise_pedidos, axis=1)\n",
        "resumo_base_pedidos_entregues = pd.DataFrame(pd.pivot_table(base_pedidos_entregues, index=['ID_SELLER','LOJISTA'], columns='status_entrega', values='COD_PEDIDO', aggfunc='count', margins=True, margins_name='TT_Pedidos_Entregues').fillna(0))\n",
        "\n",
        "\n",
        "# Prazo médio de entrega (Dias)\n",
        "resumo_base_pedidos_dias = pd.DataFrame(pd.pivot_table(base_pedidos_entregues, index=['ID_SELLER','LOJISTA'], values='Media_Entregas_Dias', aggfunc='mean').fillna(0))\n",
        "resumo_base_pedidos_dias['Media_Entregas_Dias'] = round(resumo_base_pedidos_dias['Media_Entregas_Dias'],2)\n",
        "\n",
        "\n",
        "# Prazo médio prometido\n",
        "resumo_base_pedidos_prazo_dias = pd.DataFrame(pd.pivot_table(base_pedidos_entregues, index=['ID_SELLER','LOJISTA'], values='DIAS_PRAZO', aggfunc='mean').fillna(0))\n",
        "resumo_base_pedidos_prazo_dias['DIAS_PRAZO'] = round(resumo_base_pedidos_prazo_dias['DIAS_PRAZO'],2)\n",
        "\n",
        "##################################################################### Pedidos Despachados ################################################################\n",
        "\n",
        "# Base pedidos despachado\n",
        "base_pedidos_despachado = base_pedidos_mes.query('STATUS==[\"DESPACHADO\",\"ENTREGUE\"] & DATA_DESPACHO!=\"\"').drop_duplicates()\n",
        "# Função limite de postagem\n",
        "def data_limite_postagem(base_pedidos_despachado):\n",
        "  if base_pedidos_despachado['Tipo_Envio'] == 'NSE':\n",
        "    return wd.workdays(base_pedidos_despachado['DATA_APROV'], base_pedidos_despachado['dias_prazo_nse'], country='BR')\n",
        "  elif base_pedidos_despachado['Tipo_Envio'] == 'Não' and base_pedidos_despachado['Blocado'] == 'não': \n",
        "    return wd.workdays(base_pedidos_despachado['DATA_APROV'], 2, country='BR')\n",
        "  elif base_pedidos_despachado['Tipo_Envio'] == 'Não' and base_pedidos_despachado['Blocado'] == 'sim': \n",
        "    return wd.workdays(base_pedidos_despachado['DATA_APROV'], 5, country='BR')  \n",
        "  else:\n",
        "      return \"\"  \n",
        "base_pedidos_despachado['DATA_LIMITE_POSTAGEM'] = base_pedidos_despachado.apply(data_limite_postagem, axis=1)\n",
        "\n",
        "# Função análise postagem\n",
        "def analise_postagem(base_pedidos_despachado):\n",
        "  if base_pedidos_despachado['DATA_DESPACHO'] <= base_pedidos_despachado['DATA_LIMITE_POSTAGEM']:\n",
        "    return 'postagem_dentro_prazo'\n",
        "  else:\n",
        "    return 'postagem_fora_prazo'\n",
        "base_pedidos_despachado['status_postagem'] = base_pedidos_despachado.apply(analise_postagem, axis=1)\n",
        "resumo_base_pedidos_despachado = pd.DataFrame(pd.pivot_table(base_pedidos_despachado, index=['ID_SELLER','LOJISTA'], columns='status_postagem', values='COD_PEDIDO', aggfunc='count', margins=True, margins_name='TT_Pedidos_Despachados').fillna(0))\n",
        "\n",
        "base_pedidos_despachado_v2 = base_pedidos_despachado.query('STATUS==\"DESPACHADO\"')\n",
        "\n",
        "# Gravar na tabela pedidos despachados\n",
        "dados.grava_tabela_drive('Tb_pedidos_despachados_nets', base_pedidos_despachado_v2)\n",
        "\n",
        "\n",
        "##################################################################### Pedidos Faturados e Pronto para Faturar ################################################################\n",
        "\n",
        "# Base Pedidos Faturados\n",
        "base_pedidos_faturado = base_pedidos_mes.query('STATUS==\"FATURADO\"')\n",
        "# Função limite postagem\n",
        "def data_limite_postagem(base_pedidos_faturado):\n",
        "  if base_pedidos_faturado['Tipo_Envio'] == 'NSE':\n",
        "    return wd.workdays(base_pedidos_faturado['DATA_APROV'], base_pedidos_faturado['dias_prazo_nse'], country='BR')\n",
        "  elif base_pedidos_faturado['Tipo_Envio'] == 'Não' and base_pedidos_faturado['Blocado'] == 'não': \n",
        "    return wd.workdays(base_pedidos_faturado['DATA_APROV'], 2, country='BR')\n",
        "  elif base_pedidos_faturado['Tipo_Envio'] == 'Não' and base_pedidos_faturado['Blocado'] == 'sim': \n",
        "    return wd.workdays(base_pedidos_faturado['DATA_APROV'], 5, country='BR')\n",
        "  else:\n",
        "      return \"\"    \n",
        "base_pedidos_faturado['DATA_LIMITE_POSTAGEM'] = base_pedidos_faturado.apply(data_limite_postagem, axis=1)\n",
        "\n",
        "# Base Pedidos Pronto para faturar\n",
        "\n",
        "base_pedidos_pronto_faturar = base_pedidos_mes.query('STATUS==\"PRONTO PARA FATURAR\" & DATA_APROV!=\"\"')\n",
        "# Função limite postagem\n",
        "def data_limite_postagem(base_pedidos_pronto_faturar):\n",
        "  if base_pedidos_pronto_faturar['Tipo_Envio'] == 'NSE':\n",
        "    return wd.workdays(base_pedidos_pronto_faturar['DATA_APROV'], base_pedidos_pronto_faturar['dias_prazo_nse'], country='BR')\n",
        "  elif  base_pedidos_pronto_faturar['Tipo_Envio'] == 'Não' and base_pedidos_pronto_faturar['Blocado'] == 'não': \n",
        "    return wd.workdays(base_pedidos_pronto_faturar['DATA_APROV'], 2, country='BR')\n",
        "  elif  base_pedidos_pronto_faturar['Tipo_Envio'] == 'Não' and base_pedidos_pronto_faturar['Blocado'] == 'sim': \n",
        "    return wd.workdays(base_pedidos_pronto_faturar['DATA_APROV'], 5, country='BR')  \n",
        "  else:\n",
        "      return \"\"  \n",
        "base_pedidos_pronto_faturar['DATA_LIMITE_POSTAGEM'] = base_pedidos_pronto_faturar.apply(data_limite_postagem, axis=1)\n",
        "\n",
        "# Concatenação bases\n",
        "pedidos_atraso = pd.concat([base_pedidos_faturado, base_pedidos_pronto_faturar]).drop_duplicates()\n",
        "\n",
        "######################################################################## Pedidos Cancelados #################################################################################\n",
        "\n",
        "# Base pedidos Cancelados\n",
        "base_pedidos['validacao_data'] = base_pedidos['DATA_APROV'].fillna('sem_data')\n",
        "\n",
        "def excluir_pedidos_cancelados(base_pedidos):\n",
        "    if base_pedidos['STATUS'] == 'CANCELADO' and base_pedidos['validacao_data']=='sem_data':\n",
        "        return 'excluir'\n",
        "    else:\n",
        "        return 'ok'\n",
        "\n",
        "base_pedidos['validacao_pedidos'] = base_pedidos.apply(excluir_pedidos_cancelados, axis=1)\n",
        "\n",
        "base_pedidos_v2 = base_pedidos.query('validacao_pedidos!=\"excluir\"')\n",
        "base_pedidos_v2.drop(columns=[\"validacao_pedidos\", \"validacao_data\"], inplace=True)\n",
        "\n",
        "base_cancelados = base_pedidos_v2.query('STATUS==\"CANCELADO\"')\n",
        "pedidos_cancelados = pd.DataFrame(pd.pivot_table(base_cancelados, index=['ID_SELLER','LOJISTA'], values='COD_PEDIDO_LOJA', aggfunc='count').fillna(0))\n",
        "pedidos_cancelados.rename(columns={'COD_PEDIDO_LOJA':'Pedidos_Cancelados'}, inplace=True)\n",
        "\n",
        "######################################################################### Pedidos Aprovados #################################################################################\n",
        "# Base Pedidos Aprovados\n",
        "base_aprovados = base_pedidos.query('STATUS!=\"CANCELADO\"').drop_duplicates(subset=['COD_PEDIDO'])\n",
        "pedidos_aprovados = pd.DataFrame(pd.pivot_table(base_aprovados, index=['ID_SELLER','LOJISTA'], values='DATA_APROV', aggfunc='count').fillna(0))\n",
        "pedidos_aprovados.rename(columns={'DATA_APROV':'Pedidos_Aprovados'}, inplace=True)\n",
        "\n",
        "\n",
        "######################################################################### Dados KA Nets ######################################################################################\n",
        "dados_ka = dados.consulta_bigquery('maga-bigdata', \"\"\"select * from maga-bigdata.nets_gestao_info.tgi_seller_group\"\"\")\n",
        "dados_ka.rename(columns={'group_owner':'Assistido', 'code':'ID_SELLER'}, inplace=True)\n",
        "dados_ka['Assistido'] = dados_ka['Assistido'].str.replace('Não Assistido', 'Não_Assistido')\n",
        "# Função sellers ka\n",
        "def sellers_ka(dados_ka):\n",
        "  if dados_ka['Assistido'] == 'Assistido':\n",
        "    return \"Key Account\"\n",
        "  else:\n",
        "    return 'Long Tail'\n",
        "dados_ka['Key Account?']  = dados_ka.apply(sellers_ka, axis=True)\n",
        "dados_ka_final = dados_ka[['ID_SELLER', 'Key Account?']]\n",
        "dados_ka_final['ID_SELLER'] = dados_ka_final['ID_SELLER'].apply(str)\n",
        "dados_ka_final['ID_SELLER'] = dados_ka_final['ID_SELLER'].str.strip()\n",
        "\n",
        "\n",
        "######################################################################### Base Protocolos #################################################################################\n",
        "df_protocolos = dados.busca_tabela_drive('Tabela_protocolos_sac', 'Página1')\n",
        "\n",
        "base_protocolos = df_protocolos[['Atendimento Codigo', \n",
        "                                  'Data Inicial', \n",
        "                                  'Data Final', \n",
        "                                  'Servico', \n",
        "                                  'Estagio Atual', \n",
        "                                  'Lojista Ajustado']]\n",
        "\n",
        "base_protocolos.rename(columns={'Atendimento Codigo':'Atendimento_Codigo',\n",
        "                                'Data Inicial':'Data_Inicial',\n",
        "                                'Data Final':'Data_Final',\n",
        "                                'Estagio Atual':'Estagio_Atual',\n",
        "                                'Lojista Ajustado':'Lojista_Ajustado'}, inplace=True)                                  \n",
        "\n",
        "base_protocolos['LOJISTA'] = base_protocolos['Lojista_Ajustado'].str.lower().str.strip()\n",
        "base_protocolos.rename(columns={'Atendimento_Codigo':'Protocolo'}, inplace=True)\n",
        "dinamica_protocolo = pd.pivot_table(base_protocolos, index='LOJISTA', values='Protocolo', aggfunc='count', margins=True)\n",
        "\n",
        "# Grava tabela\n",
        "#grava_tabela_drive('Tb_protocolos_nets', base_protocolos)\n",
        "base_protocolos.to_gbq(destination_table='data.Tb_protocolos_nets',project_id=projeto_gcp_2, if_exists='replace')\n",
        "\n",
        "######################################################################### Dados CR e Nps #################################################################################\n",
        "\n",
        "dados_cr_nps = dados.consulta_bigquery(projeto_gcp_1, \"\"\"SELECT Seller_id,\n",
        "                                                    round((SAFE_DIVIDE((SUM(abac_App_Site)+SUM(abac_B2B)+SUM(abac_Cadastro)+SUM(abac_Campanhas)+SUM(abac_Entrega)+SUM(abac_Ncard)+SUM(abac_Pedido)+SUM(abac_Produto)+SUM(abac_TVC)+SUM(abac_Outros)),SUM(Captado))),3) as CR_Seller,\n",
        "                                                    round((SAFE_DIVIDE((SUM(nps_promotor) - SUM(nps_detrator)),(sum(nps_detrator)+SUM(nps_promotor)+SUM(nps_neutro)))*100),2) as NPS_Seller\n",
        "                                                    FROM maga-bigdata.sac_inteligencia_clientes.sellers_netshoes_indicadores\n",
        "                                                        WHERE seller_id is not null\n",
        "                                                        AND data >= '{}'\n",
        "                                                        GROUP BY Seller_id\"\"\".format(data_base))\n",
        "\n",
        "#dados_cr_nps['CR_Seller'] = round((dados_cr_nps['CR_Seller']*100),2)\n",
        "dados_cr_nps['CR_Seller'] = pd.to_numeric(dados_cr_nps['CR_Seller']).fillna(0)\n",
        "dados_cr_nps['NPS_Seller'] = pd.to_numeric(dados_cr_nps['NPS_Seller']).fillna(0)\n",
        "dados_cr_nps['LOJISTA'] = dados_cr_nps['Seller_id'].str.lower()\n",
        "dinamica_cr_nps = dados_cr_nps[['LOJISTA', 'CR_Seller', 'NPS_Seller']].drop_duplicates(subset='LOJISTA')\n",
        "\n",
        "######################################################################### Base Hubsales #################################################################################\n",
        "# Import base\n",
        "#'/content/drive/MyDrive/Ciclo Pedidos Nets Novo/sellers Hubsales - BF.xlsx'\n",
        "base_husales = pd.read_excel('/content/drive/MyDrive/Colab_Notebooks/arquivos/ciclo_pedido/nets/sellers Hubsales - BF.xlsx', usecols=['Id Seller', \n",
        "                                                                                                                           'Nome Loja', \n",
        "                                                                                                                           'Hubsales?']).fillna(0)\n",
        "# Ajustes colunas\n",
        "base_husales.rename(columns={'Id Seller':'ID_SELLER', 'Nome Loja':'LOJISTA'}, inplace=True)\n",
        "base_husales['ID_SELLER'] = base_husales['ID_SELLER'].apply(int).apply(str)\n",
        "base_husales['LOJISTA'] = base_husales['LOJISTA'].str.lower()\n",
        "base_husales_final = base_husales[['ID_SELLER', 'Hubsales?']]\n",
        "\n",
        "\n",
        "######################################################################### Concatenação das bases #################################################################################\n",
        "\n",
        "concatencao_1 = pd.merge(base_seller_lojista,base_tt_pedidos, how='left', on=['ID_SELLER','LOJISTA','Tipo_Envio']).fillna(0).drop_duplicates()\n",
        "concatencao_2 = pd.merge(concatencao_1,resumo_base_pedidos_entregues, how='left', on=['ID_SELLER','LOJISTA']).fillna(0).drop_duplicates()\n",
        "concatencao_3 = pd.merge(concatencao_2,resumo_base_pedidos_despachado, how='left', on=['ID_SELLER','LOJISTA']).fillna(0).drop_duplicates()\n",
        "concatencao_4 = pd.merge(concatencao_3,pedidos_cancelados, how='left', on=['ID_SELLER']).fillna(0).drop_duplicates()\n",
        "concatencao_5 = pd.merge(concatencao_4,pedidos_aprovados, how='left', on=['ID_SELLER','LOJISTA']).fillna(0).drop_duplicates()\n",
        "concatencao_6 = pd.merge(concatencao_5,dados_ka_final, how='left', on=['ID_SELLER']).fillna('Não').drop_duplicates()\n",
        "#concatencao_7 = pd.merge(concatencao_6,base_nse_final, how='left', on=['ID_SELLER']).fillna('Não').drop_duplicates()\n",
        "concatencao_7 = pd.merge(concatencao_6,dinamica_protocolo, how='left', on=['LOJISTA']).fillna(0).drop_duplicates()\n",
        "concatencao_8 = pd.merge(concatencao_7,dinamica_cr_nps, how='left', on=['LOJISTA']).fillna(0).drop_duplicates()\n",
        "concatencao_9 = pd.merge(concatencao_8,base_husales_final, how='left', on=['ID_SELLER']).fillna(\"Não\").drop_duplicates()\n",
        "concatencao_10 = pd.merge(concatencao_9,resumo_base_pedidos_dias, how='left', on=['ID_SELLER','LOJISTA']).fillna(0).drop_duplicates()\n",
        "concatencao_11 = pd.merge(concatencao_10,resumo_base_pedidos_prazo_dias, how='left', on=['ID_SELLER','LOJISTA']).fillna(0).drop_duplicates()\n",
        "concatencao_12 = pd.merge(concatencao_11, reclamacoes_formais_resumo, how='left', on='LOJISTA').fillna(0)\n",
        "\n",
        " ######################################################################### Indicador de reputação #################################################################################\n",
        "# Criar colunas de participação\n",
        "concatencao_12['% Entrega'] = round((concatencao_12['entregue_dentro_prazo']/concatencao_12['TT_Pedidos'])*100,2)\n",
        "concatencao_12['% Postagem'] = round((concatencao_12['postagem_dentro_prazo']/concatencao_12['TT_Pedidos'])*100,2)\n",
        "concatencao_12['% Cancelados'] = round((concatencao_12['Pedidos_Cancelados']/concatencao_12['TT_Pedidos'])*100,2)\n",
        "concatencao_12['% Reclamação'] = round((concatencao_12['Qtd_Reclamacoes_Formais']/concatencao_12['TT_Pedidos'])*100,2)\n",
        "\n",
        "# Classificação  regua entrega, despacho, cancelados, reclamação e nps\n",
        "def regra_entrega(concatencao_12):\n",
        "  if concatencao_12['% Entrega'] >= 0.0 and concatencao_12['% Entrega'] <= 84.99:\n",
        "    return 1\n",
        "  elif concatencao_12['% Entrega'] >= 85 and concatencao_12['% Entrega'] <= 88.99:\n",
        "    return 2\n",
        "  elif concatencao_12['% Entrega'] >= 89 and concatencao_12['% Entrega'] <= 92.99:\n",
        "    return 3\n",
        "  elif concatencao_12['% Entrega'] >= 93 and concatencao_12['% Entrega'] <= 94.99:\n",
        "    return 4\n",
        "  elif concatencao_12['% Entrega'] >= 95:\n",
        "    return 5\n",
        "concatencao_12['reg_entrega'] = concatencao_12.apply(regra_entrega, axis=1)\n",
        "\n",
        "\n",
        "def regra_despacho(concatencao_12):\n",
        "  if concatencao_12['% Postagem'] >= 0.0 and concatencao_12['% Postagem'] <= 84.99:\n",
        "    return 1\n",
        "  elif concatencao_12['% Postagem'] >= 85 and concatencao_12['% Postagem'] <= 88.99:\n",
        "    return 2\n",
        "  elif concatencao_12['% Postagem'] >= 89 and concatencao_12['% Postagem'] <= 92.99:\n",
        "    return 3\n",
        "  elif concatencao_12['% Postagem'] >= 93 and concatencao_12['% Postagem'] <= 94.99:\n",
        "    return 4\n",
        "  elif concatencao_12['% Postagem'] >= 95:\n",
        "    return 5\n",
        "concatencao_12['reg_Postagem'] = concatencao_12.apply(regra_despacho, axis=1)\n",
        "\n",
        "\n",
        "def regra_cancelados(concatencao_12):\n",
        "  if concatencao_12['% Cancelados'] <= 2.0:\n",
        "    return 5\n",
        "  elif concatencao_12['% Cancelados'] >= 2.01 and concatencao_12['% Cancelados'] <= 3.0:\n",
        "    return 4\n",
        "  elif concatencao_12['% Cancelados'] >= 3.01 and concatencao_12['% Cancelados'] <= 4.0:\n",
        "    return 3\n",
        "  elif concatencao_12['% Cancelados'] >= 4.01 and concatencao_12['% Cancelados'] <= 5.0:\n",
        "    return 2\n",
        "  elif concatencao_12['% Cancelados'] >= 5.01:\n",
        "    return 1\n",
        "concatencao_12['reg_Cancelados'] = concatencao_12.apply(regra_cancelados, axis=1)\n",
        "\n",
        "\n",
        "def regra_reclamacao(concatencao_12):\n",
        "  if concatencao_12['% Reclamação'] <= 1.0:\n",
        "    return 5\n",
        "  elif concatencao_12['% Reclamação'] >= 1.01 and concatencao_12['% Reclamação'] <= 2.50:\n",
        "    return 4\n",
        "  elif concatencao_12['% Reclamação'] >= 2.51 and concatencao_12['% Reclamação'] <= 3.50:\n",
        "    return 3\n",
        "  elif concatencao_12['% Reclamação'] >= 3.51 and concatencao_12['% Reclamação'] <= 4.00:\n",
        "    return 2\n",
        "  elif concatencao_12['% Reclamação'] >= 4.01:\n",
        "    return 1\n",
        "concatencao_12['reg_Reclamação'] = concatencao_12.apply(regra_cancelados, axis=1)\n",
        "\n",
        "\n",
        "def regra_nps(concatencao_12):\n",
        "  if concatencao_12['NPS_Seller'] <= 64.9 :\n",
        "    return 1\n",
        "  elif concatencao_12['NPS_Seller'] >= 65.00 and concatencao_12['NPS_Seller'] <= 67.99:\n",
        "    return 2\n",
        "  elif concatencao_12['NPS_Seller'] >= 68.00 and concatencao_12['NPS_Seller'] <= 70.00:\n",
        "    return 3\n",
        "  elif concatencao_12['NPS_Seller'] >= 70.01 and concatencao_12['NPS_Seller'] <= 74.99:\n",
        "    return 4\n",
        "  elif concatencao_12['NPS_Seller'] >= 75.00:\n",
        "    return 5\n",
        "concatencao_12['reg_nps'] = concatencao_12.apply(regra_nps, axis=1)\n",
        "\n",
        "\n",
        "def regra_cr(concatencao_12):\n",
        "  if concatencao_12['CR_Seller'] >= 0.301 :\n",
        "    return 1\n",
        "  elif concatencao_12['CR_Seller'] >= 0.201 and concatencao_12['CR_Seller'] <= 0.300:\n",
        "    return 2\n",
        "  elif concatencao_12['CR_Seller'] >= 0.151 and concatencao_12['CR_Seller'] <= 0.200:\n",
        "    return 3\n",
        "  elif concatencao_12['CR_Seller'] >= 0.101 and concatencao_12['CR_Seller'] <= 0.150:\n",
        "    return 4\n",
        "  elif concatencao_12['CR_Seller'] <= 0.100:\n",
        "    return 5\n",
        "concatencao_12['reg_cr'] = concatencao_12.apply(regra_cr, axis=1)\n",
        "\n",
        "\n",
        "# Indicador da reputação\n",
        "def funcao_reputacao(concatencao_12):\n",
        "  if concatencao_12['Tipo_Envio'] == 'Não':\n",
        "    return round((concatencao_12['reg_nps']/5*1.45)+(concatencao_12['reg_entrega']/5*1.50)+(concatencao_12['reg_cr']/5*0.50)+(concatencao_12['reg_Reclamação']/5*0.35)+(concatencao_12['reg_Cancelados']/5*1.20),2)\n",
        "  elif concatencao_12['Tipo_Envio'] == 'NSE':\n",
        "    return round((concatencao_12['reg_nps']/5*1.45)+(concatencao_12['reg_Postagem']/5*1.50)+(concatencao_12['reg_cr']/5*0.50)+(concatencao_12['reg_Reclamação']/5*0.35)+(concatencao_12['reg_Cancelados']/5*1.20),2)\n",
        "concatencao_12['Indicador_Reputacao'] = concatencao_12.apply(funcao_reputacao, axis=1)\n",
        "\n",
        "######################################################################### Base pedidos atrasados #################################################################################\n",
        "# Base Pedidos em atrasados\n",
        "reputacao = concatencao_12[['ID_SELLER', 'Indicador_Reputacao']]\n",
        "pedidos_atraso_reputacao = pd.merge(pedidos_atraso, reputacao, how='left', on='ID_SELLER')\n",
        "# Coluna ontem\n",
        "pedidos_atraso_reputacao['Ontem'] = pedidos_atraso_reputacao['Hoje'] - datetime.timedelta(days = 1)\n",
        "# Coluna Pedidos Atrasados\n",
        "def pedidos_em_atraso(pedidos_atraso_reputacao):\n",
        "  if pedidos_atraso_reputacao['DATA_PROMETIDA'] <= pedidos_atraso_reputacao['Ontem']: \n",
        "    return 'Pedido_Atrasado'\n",
        "  else:\n",
        "    return ''\n",
        "pedidos_atraso_reputacao['Pedidos_Atrasados'] =  pedidos_atraso_reputacao.apply(pedidos_em_atraso, axis=1)   \n",
        "\n",
        "# Coluna Expedição  Atrasada\n",
        "def expedicao_em_atraso(pedidos_atraso_reputacao):\n",
        "  if pedidos_atraso_reputacao['DATA_LIMITE_POSTAGEM'] <= pedidos_atraso_reputacao['Ontem']: \n",
        "    return 'Expedicao_Atrasada'\n",
        "  else:\n",
        "    return ''\n",
        "pedidos_atraso_reputacao['Pedidos_Expedicao_Atrasada'] =  pedidos_atraso_reputacao.apply(expedicao_em_atraso, axis=1)\n",
        "\n",
        "# Grava tabela \n",
        "dados.grava_tabela_drive('Tb_pedidos_atrasados',pedidos_atraso_reputacao)\n",
        "\n",
        "######################################################################### Resumo pedidos atrasados e expedição atrasados #################################################################################\n",
        "\n",
        "base1 = pedidos_atraso_reputacao.query('Pedidos_Atrasados==\"Pedido_Atrasado\"').drop_duplicates(subset=['ID_SELLER', 'COD_PEDIDO_LOJA'])\n",
        "resumo_base1 = pd.pivot_table(base1, index='ID_SELLER', values=['Pedidos_Atrasados'], aggfunc='count')\n",
        "base2 = pedidos_atraso_reputacao.query('Pedidos_Expedicao_Atrasada==\"Expedicao_Atrasada\"').drop_duplicates(subset=['ID_SELLER', 'COD_PEDIDO_LOJA'])\n",
        "resumo_base2 = pd.pivot_table(base2, index='ID_SELLER', values=['Pedidos_Expedicao_Atrasada'], aggfunc='count')\n",
        "\n",
        "######################################################################### Concatenação das bases v2 #################################################################################\n",
        " \n",
        "concatencao_14 = pd.merge(concatencao_12,resumo_base1, how='left', on='ID_SELLER')\n",
        "concatencao_15 = pd.merge(concatencao_14,resumo_base2, how='left', on='ID_SELLER')\n",
        "\n",
        "######################################################################### Base GMV ###################################################################################################\n",
        "\n",
        "base_pedidos_mes_gmv = pd.pivot_table(base_pedidos_mes, index='ID_SELLER', values='VLR', aggfunc='sum')\n",
        "base_pedidos_mes_gmv.rename(columns={'VLR':'GMV'}, inplace=True)\n",
        "\n",
        "######################################################################### Concatenação das bases v3 #################################################################################\n",
        "\n",
        "concatencao_16 = pd.merge(concatencao_15, base_pedidos_mes_gmv, how='left', on='ID_SELLER')\n",
        "concatencao_16['GMV'] = concatencao_16['GMV'].astype(float)\n",
        "concatencao_16['GMV'] = round(concatencao_16['GMV'],2)\n",
        "# GRavar tabela Resumo\n",
        "dados.grava_tabela_drive('Tb_Pedidos_Nets_Novo', concatencao_16)\n",
        "\n",
        "######################################################################### Resumo mensal ciclo pedido #################################################################################\n",
        "\n",
        "# Base Pedidos resumo ciclo - mês a mês\n",
        "base_pedidos_ciclo = base_pedidos.query('STATUS!=\"CANCELADO\" & MES_DATA_PEDIDO==6').drop_duplicates()\n",
        "# Total pedidos\n",
        "tt_pedidos = pd.pivot_table(base_pedidos_ciclo, index=['ID_SELLER', 'LOJISTA'], values='COD_PEDIDO', aggfunc='count').fillna(0)\n",
        "tt_pedidos.rename(columns={'COD_PEDIDO':'TT_pedidos'}, inplace=True)\n",
        "# Pedidos aprovados\n",
        "pedidos_aprovados_v2 = pd.DataFrame(pd.pivot_table(base_pedidos_ciclo, index=['ID_SELLER','LOJISTA'], values='DATA_APROV', aggfunc='count').fillna(0))\n",
        "pedidos_aprovados_v2.rename(columns={'DATA_APROV':'Pedidos_Aprovados'}, inplace=True)\n",
        "# Pedidos faturado\n",
        "base_pedidos_ciclo_faturado = base_pedidos.query('MES_DATA_PEDIDO==6 & STATUS==\"FATURADO\"').drop_duplicates()\n",
        "base_pedidos_ciclo_faturado_v2 = pd.pivot_table(base_pedidos_ciclo_faturado, index=['ID_SELLER', 'LOJISTA'], values='COD_PEDIDO', aggfunc='count').fillna(0)\n",
        "base_pedidos_ciclo_faturado_v2.rename(columns={'COD_PEDIDO':'Pedidos_Faturados'}, inplace=True)\n",
        "# Pedidos pronto para faturar\n",
        "base_pedidos_ciclo_pronto = base_pedidos.query(' MES_DATA_PEDIDO==6 & STATUS==\"PRONTO PARA FATURAR\"').drop_duplicates()\n",
        "base_pedidos_ciclo_pronto_v2 = pd.pivot_table(base_pedidos_ciclo_pronto, index=['ID_SELLER', 'LOJISTA'], values='COD_PEDIDO', aggfunc='count').fillna(0)\n",
        "base_pedidos_ciclo_pronto_v2.rename(columns={'COD_PEDIDO':'Pedidos_pronto_faturar'}, inplace=True)\n",
        "# Pedidos Expedição atrasada\n",
        "pedidos_expedicao = pedidos_atraso_reputacao.query('MES_DATA_PEDIDO==6 & Pedidos_Expedicao_Atrasada==\"Expedicao_Atrasada\"').drop_duplicates()\n",
        "pedidos_expedicao_v2 = pd.pivot_table(pedidos_expedicao, index='ID_SELLER', values=['Pedidos_Expedicao_Atrasada'], aggfunc='count')\n",
        "\n",
        "# Concatenação das bases\n",
        "concat_ciclo = pd.merge(base_seller_lojista, tt_pedidos, how='left', on=['ID_SELLER', 'LOJISTA']).fillna(0).drop_duplicates()\n",
        "concat_ciclo_v2 = pd.merge(concat_ciclo, pedidos_aprovados_v2, how='left', on=['ID_SELLER', 'LOJISTA']).fillna(0).drop_duplicates()\n",
        "concat_ciclo_v3 = pd.merge(concat_ciclo_v2, base_pedidos_ciclo_faturado_v2, how='left', on=['ID_SELLER', 'LOJISTA']).fillna(0).drop_duplicates()\n",
        "concat_ciclo_v4 = pd.merge(concat_ciclo_v3, base_pedidos_ciclo_pronto_v2, how='left', on=['ID_SELLER', 'LOJISTA']).fillna(0).drop_duplicates()\n",
        "concat_ciclo_v5 = pd.merge(concat_ciclo_v4, pedidos_expedicao_v2, how='left', on=['ID_SELLER']).fillna(0).drop_duplicates()\n",
        "\n",
        "# Base protocolos mês\n",
        "base_protocolos_ciclo_v2 = dados.consulta_bigquery('marketplace-analytics-333712', \"\"\"SELECT * FROM `marketplace-analytics-333712.data.Tb_protocolos_nets` \n",
        "                                                                                WHERE parse_date('%d/%m/%Y', Data_Inicial) >= '2022-06-01'\n",
        "                                                                                and Data_Inicial not in ('AtendimentoDataInicial')\"\"\")\n",
        "dinamica_protocolo_v2 = pd.pivot_table(base_protocolos_ciclo_v2, index='LOJISTA', values='Protocolo', aggfunc='count', margins=True)\n",
        "concat_ciclo_v6 = pd.merge(concat_ciclo_v5, dinamica_protocolo_v2, how='left', on=['LOJISTA']).fillna(0).drop_duplicates()\n",
        "\n",
        "# Pedidos enviados\n",
        "base_pedidos_enviados = base_pedidos.query('STATUS==[\"ENTREGUE\",\"DESPACHADO\"]  & MES_DATA_PEDIDO==6').drop_duplicates()\n",
        "base_pedidos_enviados_v2 = pd.pivot_table(base_pedidos_enviados, index=['ID_SELLER', 'LOJISTA'], values='COD_PEDIDO', aggfunc='count').fillna(0)\n",
        "base_pedidos_enviados_v2.rename(columns={'COD_PEDIDO':'Pedidos_Enviados'}, inplace=True)\n",
        "concat_ciclo_v7 = pd.merge(concat_ciclo_v6, base_pedidos_enviados_v2, how='left', on=['ID_SELLER', 'LOJISTA']).fillna(0).drop_duplicates()\n",
        "\n",
        "# Gravar tabela\n",
        "dados.grava_tabela_drive('Resumo_mes_ciclo_pedido', concat_ciclo_v7)\n",
        "print('Ciclo pedido atualizado!')"
      ],
      "metadata": {
        "id": "DqJuwFIIpRJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534616a6-34db-4079-fbdc-1aa8c1acd854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bloco executado\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:373: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:374: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:380: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/workadays/workdays.py:38: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
            "  while dt_aux in holidays or is_weekend(dt_aux):\n",
            "/usr/local/lib/python3.7/dist-packages/workadays/workdays.py:52: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
            "  if dt_aux in holidays:\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:407: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:438: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:438: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:453: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:453: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:497: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:498: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:517: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "1it [00:06,  6.73s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciclo pedido atualizado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEQgyFh9BcV1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise Pedidos : Entregues e Despachados"
      ],
      "metadata": {
        "id": "uzl3m1LON14U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exportar para tabela BigQuery (análise pedido entregues)\n",
        "#data_pedidos_entregues = (datetime.datetime.now() - datetime.timedelta(90)).strftime('%Y-%m-%d')\n",
        "base_efetividade_entrega = dados.consulta_bigquery(projeto_gcp_1, \"\"\"Select distinct\n",
        "                                                                        shp.seller_name as LOJISTA,\n",
        "                                                                        shp.seller_id as ID_SELLER,\n",
        "                                                                        os.code as COD_PEDIDO_LOJA,\n",
        "                                                                        osh.delivery_id as COD_PEDIDO,\n",
        "                                                                        cast(dispatch_date as date) as DATA_DESPACHO,\n",
        "                                                                        cast(delivered_date as date) as DATA_ENTREGA,\n",
        "                                                                        cast(os.sale_date as date) as DATA_PEDIDO,\n",
        "                                                                        cast(osh.billing_date as date) as DATA_FATURADO,\n",
        "                                                                        --cast(payment_confirmation_date as date) as DATA_CONFIR_PGTO,\n",
        "                                                                        cast(first_date_payment as date) as DATA_APROV,\n",
        "                                                                        cast(expected_delivery_date as date) as DATA_PROMETIDA,\n",
        "                                                                        store_code as UNI_NEG,\n",
        "                                                                        dead_line_in_days as DIAS_PRAZO,\n",
        "                                                                        osh.shipping_status_name as STATUS, \n",
        "                                                                        shipping_address_city as MUNICIPIO,\n",
        "                                                                        shipping_address_state_code as ESTADO,\n",
        "                                                                        ad.postal_code as CEP,\n",
        "                                                                        n.Ns_Entregas as Tipo_Envio,\n",
        "                                                                        --sum((shp.value_placed) + (case when shp.seller_id != '0' then shp.value_freight else 0 end)) as VLR,\n",
        "                                                                        sum(case when osh.billing_date is null then 0 else (shp.value_placed) + (case when shp.seller_id != '0' then osh.freight else 0 end) end) as VLR,\n",
        "                                                                        sum(shp.value_freight) as FRETE\n",
        "                                                                    FROM `maga-bigdata.netshoes_dw.vw_order_full` os, \n",
        "                                                                    unnest(os.order_shipping) osh,  unnest(osh.shipping_product) shp, unnest(shipping_status_history) hist\n",
        "                                                                    left join maga-bigdata.netshoes_dw.vw_order_address_shipping ad on ad.order_id = os.order_id and ad.order_shipping_id = osh.order_shipping_id\n",
        "                                                                    left join maga-bigdata.marketplace_analytics.sellers_nets_nse as n on n.ID_SELLER = shp.seller_id\n",
        "                                                                    \n",
        "                                                                            where\n",
        "                                                                            cast(os.sale_date as date) between '2022-04-01' and current_date()\n",
        "                                                                            --EXTRACT(YEAR FROM date(expected_delivery_date)) = 2022\n",
        "                                                                            --and EXTRACT(MONTH FROM date(expected_delivery_date)) = 06\n",
        "                                                                            --and date(expected_delivery_date) <= current_date() \n",
        "                                                                            and os.code not like '%T%'\n",
        "                                                                            and shp.source = '3P' \n",
        "                                                                            and os.is_ignore_pickup = false\n",
        "                                                                            and NOT(os.amount >= 50000 AND osh.status = 12) \n",
        "                                                                            and IFNULL(cancel_code,0) <> 100 \n",
        "                                                                            and osh.shipping_status_name in ('DESPACHADO', 'ENTREGUE', 'FATURADO', 'PRONTO PARA FATURAR')\n",
        "                                                                            group by \n",
        "                                                                            1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17\"\"\")\n",
        "\n",
        "base_efetividade_entrega.to_gbq(destination_table='marketplace_analytics.Tb_pedidos_entregues_nets', project_id=projeto_gcp_1, if_exists='replace')\n",
        "\n",
        "print(\"\\nTabela Entregues e Despachados - Atualizada!\")"
      ],
      "metadata": {
        "id": "K2-L9pPINN-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxhyqOGRJ1IV"
      },
      "source": [
        "Nps Nets - Seller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKCSs30avihf"
      },
      "outputs": [],
      "source": [
        "# Quantidade de pedidos por seller e por mês\n",
        "quantidade_sellers = pd.pivot_table(base_pedidos_mes, index='LOJISTA', columns='mes_data_aprovacao', values='COD_PEDIDO_LOJA',aggfunc='count').fillna(0)\n",
        "quantidade_sellers_concatencao_12 = pd.merge(concatencao_12, quantidade_sellers, how='left', on='LOJISTA')\n",
        "\n",
        "\n",
        "dados.grava_tabela_drive('NPS_Seller', quantidade_sellers_concatencao_12)\n",
        "\n",
        "print(\"Tabela NPS Nets - Atualizada!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRYoT6ahYyT-"
      },
      "source": [
        "Acompanhamento Black"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxrgudZhvibE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Acompanhamento Black\n",
        "#/content/drive/MyDrive/Ciclo Pedidos Nets Novo/Dash - Ciclo Pedidos Base.xlsx\n",
        "dash = pd.read_excel('/content/drive/MyDrive/Ciclo Pedidos Nets Novo/Dash - Ciclo Pedidos Base.xlsx', sheet_name='Dash', skiprows=2,usecols=['Loja',\n",
        "                                                                                                                                                'Ns Entregas?',\n",
        "                                                                                                                                                'Hubsales',\n",
        "                                                                                                                                                'Carteira',\n",
        "                                                                                                                                                'Blocado?',\n",
        "                                                                                                                                                'Status Seller',\n",
        "                                                                                                                                                'Pausada?'])\n",
        "\n",
        "\n",
        "# Renomear coluna \n",
        "dash.rename(columns={'Loja':'LOJISTA'}, inplace=True)\n",
        "\n",
        "# Base de pedidos sem checkin\n",
        "base_pedidos['STATUS'] = base_pedidos['STATUS'].str.strip() \n",
        "# Remover cancelados                                         \n",
        "base_nets_original_sem_cancelados =  base_pedidos.query('STATUS!=\"CANCELADO\" & STATUS!=\"ENTREGUE\"')                                         \n",
        "                          \n",
        "base_nets_original_sem_cancelados['check_pedidos_loja'] = base_nets_original_sem_cancelados['COD_PEDIDO_LOJA'].str.contains(\"T\")\n",
        "base_1 = base_nets_original_sem_cancelados.query('check_pedidos_loja==False')\n",
        "\n",
        "\n",
        "base_1['DIAS_PRAZO'] = base_1['DIAS_PRAZO'].replace('','0')\n",
        "base_1['DIAS_PRAZO'] = base_1['DIAS_PRAZO'].astype('int64')\n",
        "base_1['DATA_PEDIDO'] = base_1['DATA_PEDIDO'].astype(object)\n",
        "base_1['DATA_PEDIDO'] = pd.to_datetime(base_1['DATA_PEDIDO'], format='%Y%m%d')\n",
        "base_1['DATA_APROV'] = base_1['DATA_APROV'].astype(object)\n",
        "base_1['DATA_APROV'] = pd.to_datetime(base_1['DATA_APROV'], format='%Y%m%d')\n",
        "\n",
        "base_1['DATA_ENTREGA'] = base_1['DATA_ENTREGA'].astype(object)\n",
        "base_1['DATA_ENTREGA'] = pd.to_datetime(base_1['DATA_ENTREGA'])\n",
        "\n",
        "def data_dias_uteis(base_1):\n",
        "    return wd.workdays(base_1['DATA_APROV'], base_1['DIAS_PRAZO'], country=None)\n",
        "\n",
        "base_1['DATA_PROMETIDA'] = base_1.apply(data_dias_uteis, axis=1)\n",
        "base_1['mes'] = base_1['DATA_PROMETIDA'].dt.month\n",
        "\n",
        "base_1['hoje'] = datetime.datetime.today().strftime('%Y-%m-%d')\n",
        "base_1['hoje'] = pd.to_datetime(base_1['hoje'])\n",
        "\n",
        "base_2 = base_1.query('mes == 1')\n",
        "\n",
        "# Tratamento dos dados\n",
        "\n",
        "base_nets_s_entregues_dash = pd.merge(base_2, dash, how='left', on='LOJISTA')\n",
        "base_nets_s_entregues_dash['DATA_APROV'] = pd.to_datetime(base_nets_s_entregues_dash['DATA_APROV'])\n",
        "base_nets_s_entregues_dash['DAT_CRIA_PEDIDO'] = pd.to_datetime(base_nets_s_entregues_dash['DAT_CRIA_PEDIDO'], infer_datetime_format=True)\n",
        "\n",
        "base_nets_s_entregues_dash.rename(columns={'Ns Entregas?':'Ns_Entregas',\n",
        "                                           'Blocado?':'Blocado',\n",
        "                                           'Status Seller':'Status_Seller',\n",
        "                                           'Pausada?':'Pausada'}, inplace=True)\n",
        "\n",
        "def data_limite_postagem(base_nets_s_entregues_dash):\n",
        "  if base_nets_s_entregues_dash['Blocado'] == 'Blocado':\n",
        "    return wd.workdays(base_nets_s_entregues_dash['DATA_APROV'], 5 , country=None)\n",
        "  else:\n",
        "    return wd.workdays(base_nets_s_entregues_dash['DATA_APROV'], 2 , country=None)\n",
        "\n",
        "  \n",
        "base_nets_s_entregues_dash['DATA_LIMITE_POSTAGEM'] = base_nets_s_entregues_dash.apply(data_limite_postagem, axis=1)\n",
        "\n",
        "def nome(base_nets_s_entregues_dash):\n",
        "  string_nova = unidecode.unidecode(base_nets_s_entregues_dash)\n",
        "  return string_nova\n",
        "\n",
        "base_nets_s_entregues_dash['LOJISTA'] = base_nets_s_entregues_dash['LOJISTA'].apply(nome)\n",
        "base_nets_s_entregues_dash['LOJISTA'] = base_nets_s_entregues_dash['LOJISTA'].str.lower().str.replace(' ', '').str.replace(\"'\",\"\").str.replace('.','')\n",
        "\n",
        "# Tratativa Municipio\n",
        "base_nets_s_entregues_dash_v2 = base_nets_s_entregues_dash.query('MUNICIPIO!=\"566.914.590-91\" & MUNICIPIO!=\"29780000\" & MUNICIPIO!=\"28400-000\" & MUNICIPIO!=\"89211-460\"')\n",
        "base_nets_s_entregues_dash_v2.head(1)\n",
        "\n",
        "\n",
        "print(\"Gravando na tabela.........\")\n",
        "\n",
        "# Gravar na tabela dia atual\n",
        "def input_drive():\n",
        "    #Abrir planilha e primeira aba\n",
        "    pagina = gc.open('Tb_acompanhamento_black_nets').sheet1\n",
        "    #Limpar base\n",
        "    pagina.clear()\n",
        "    #Importar dataframe na planilha\n",
        "    return set_with_dataframe(pagina, base_nets_s_entregues_dash_v2, include_column_header=True)\n",
        "input_drive()\n",
        "print(\"-----------------\")\n",
        "print(\"Tabela Atualizada\")\n",
        "print(\"-----------------\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XqF7KX-34kF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Dados pedidos processados 3p 2021\n",
        "# projeto\n",
        "maga_bigdata = 'maga-bigdata'\n",
        "#autenticação e select\n",
        "client = bigquery.Client(project=maga_bigdata)\n",
        "sql = \"\"\"SELECT * FROM `maga-bigdata.marketplace_analytics.pedidos_processados_2021_3p`\"\"\"\n",
        "\n",
        "# Select salvo na variavel\n",
        "pedidos_2021 = client.query(sql).to_dataframe().fillna(\"\")\n",
        "pedidos_2021.head()\n",
        "\n",
        "pedidos_2021['data_pedido_processado'] = pd.to_datetime(pedidos_2021['data_pedido_processado'])\n",
        "pedidos_2021['mes'] = pedidos_2021['data_pedido_processado'].dt.month\n",
        "resumo = pd.pivot_table(pedidos_2021, index='seller_id', columns='mes', values='pedido_processado', aggfunc='sum').fillna(0)\n",
        "resumo.to_excel('/content/drive/MyDrive/dados_pedidos/Magalu/pedidos_processados_3p_2021.xlsx')\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''base_analise = dados.consulta_bigquery(projeto_gcp_1,\"\"\"Select distinct\n",
        "                                                        shp.seller_name as LOJISTA,\n",
        "                                                        shp.seller_id as ID_SELLER,\n",
        "                                                        os.code as COD_PEDIDO_LOJA,\n",
        "                                                        osh.delivery_id as COD_PEDIDO,\n",
        "                                                        cast(dispatch_date as date) as DATA_DESPACHO,\n",
        "                                                        cast(delivered_date as date) as DATA_ENTREGA,\n",
        "                                                        cast(os.sale_date as date) as DATA_PEDIDO,\n",
        "                                                        cast(osh.billing_date as date) as DATA_FATURADO,\n",
        "                                                        --cast(payment_confirmation_date as date) as DATA_CONFIR_PGTO,\n",
        "                                                        cast(first_date_payment as date) as DATA_APROV,\n",
        "                                                        cast(expected_delivery_date as date) as DATA_PROMETIDA,\n",
        "                                                        store_code as UNI_NEG,\n",
        "                                                        dead_line_in_days as DIAS_PRAZO,\n",
        "                                                        osh.shipping_status_name as STATUS, \n",
        "                                                        shipping_address_city as MUNICIPIO,\n",
        "                                                        shipping_address_state_code as ESTADO,\n",
        "                                                        ad.postal_code as CEP,\n",
        "                                                        n.Ns_Entregas as Tipo_Envio,\n",
        "                                                        (case when d.default_handling_time is null then 0 else (d.default_handling_time/24) end) as dias_prazo_nse,\n",
        "                                                        --sum((shp.value_placed) + (case when shp.seller_id != '0' then shp.value_freight else 0 end)) as VLR,\n",
        "                                                        sum(case when osh.billing_date is null then 0 else (shp.value_placed) + (case when shp.seller_id != '0' then osh.freight else 0 end) end) as VLR,\n",
        "                                                        sum(shp.value_freight) as FRETE\n",
        "                                                    FROM `maga-bigdata.netshoes_dw.vw_order_full` os, \n",
        "                                                    unnest(os.order_shipping) osh,  unnest(osh.shipping_product) shp, unnest(shipping_status_history) hist\n",
        "                                                    left join maga-bigdata.netshoes_dw.vw_order_address_shipping ad on ad.order_id = os.order_id and ad.order_shipping_id = osh.order_shipping_id\n",
        "                                                    left join maga-bigdata.marketplace_analytics.sellers_nets_nse as n on n.ID_SELLER = shp.seller_id\n",
        "                                                    left join (SELECT\n",
        "                                                                    --id,\n",
        "                                                                    seller_name,\n",
        "                                                                    default_handling_time,\n",
        "                                                                    name\n",
        "                                                                FROM\n",
        "                                                                    maga-bigdata.maga_onboarding.distribution_center dc\n",
        "                                                                JOIN\n",
        "                                                                    maga-bigdata.maga_onboarding.handling_time ht ON ht.id = dc.handling_time_id\n",
        "                                                                JOIN\n",
        "                                                                    maga-bigdata.maga_onboarding.origin_address oa ON oa.id = dc.address_id\n",
        "                                                                JOIN\n",
        "                                                                    maga-bigdata.maga_onboarding.distribution_center_organizations dco ON dco.distributioncenter_id = dc.id\n",
        "                                                                JOIN\n",
        "                                                                    maga-bigdata.maga_onboarding.organization o ON o.id = dco.organization_id\n",
        "                                                                    where name='netshoes'\n",
        "                                                                    group by seller_name,default_handling_time, name) as d on d.seller_name = shp.seller_id\n",
        "\n",
        "                                                        \n",
        "                                                            where\n",
        "                                                            cast(first_date_payment as date) >= '2022-04-01'\n",
        "                                                            --EXTRACT(YEAR FROM date(expected_delivery_date)) = 2022\n",
        "                                                            --and EXTRACT(MONTH FROM date(expected_delivery_date)) = 06\n",
        "                                                            --and date(expected_delivery_date) <= current_date() \n",
        "                                                            and os.code not like '%T%'\n",
        "                                                            and shp.source = '3P' \n",
        "                                                            and os.is_ignore_pickup = false\n",
        "                                                            and NOT(os.amount >= 50000 AND osh.status = 12) \n",
        "                                                            and IFNULL(cancel_code,0) <> 100 \n",
        "                                                            and osh.shipping_status_name in ('DESPACHADO', 'FATURADO', 'PRONTO PARA FATURAR')\n",
        "                                                            and n.Ns_Entregas = 'NSE'\n",
        "                                                            group by \n",
        "                                                            1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18\"\"\")\n",
        "\n",
        "                                                            pedidos_ckeckin = dados.consulta_bigquery(projeto_gcp_1,\"\"\"SELECT DISTINCT\n",
        "                                                            A.PEDS_COD COD_PEDIDO,\n",
        "                                                            --A.PEDS_EXT_COD PEDIDO_EXTERNO,\n",
        "                                                            --B.TROD_COD CODIGO_DA_TROCA,\n",
        "                                                            B.TROD_STR_STA STATUS_checkin,\n",
        "                                                            --C.ITET_DAT_PROENT DATA_CHECKIN\n",
        "                                                            FROM `maga-bigdata.abacos_nets.aba_tcom_pedsai` A\n",
        "                                                            INNER JOIN `maga-bigdata.abacos_nets.aba_ttrd_trodev` B ON A.CLIF_COD = B.CLIF_COD\n",
        "                                                            INNER JOIN `maga-bigdata.abacos_nets.aba_ttrd_itetrd` C ON B.TROD_COD = C.TROD_COD\n",
        "                                                            --WHERE A.PEDS_COD IN ('XXX')\n",
        "                                                            WHERE B.TROD_STR_STA = 'Finalizado'\t\n",
        "                                                                --AND PEDS_VAL_PED = ITET_VAL_PRETOT\n",
        "                                                                AND ITET_DAT_PROENT IS NOT NULL\n",
        "                                                                AND ITET_DAT_PROENT >='2019-01-01'\n",
        "                                                                --AND B.TROD_DAT_PRAPRO >= '2021-09-01'\n",
        "                                                                --and A.PEDS_COD = 863085411\n",
        "                                                            group by A.PEDS_COD, B.TROD_STR_STA\"\"\")\n",
        "\n",
        "pedidos_ckeckin['COD_PEDIDO'] = pedidos_ckeckin['COD_PEDIDO'].astype(str)\n",
        "base_analise_checkin = pd.merge(base_analise, pedidos_ckeckin, how='left', on='COD_PEDIDO')\n",
        "base_analise_checkin_v2 = base_analise_checkin.query('STATUS_checkin!=\"Finalizado\"')\n",
        "base_analise_checkin_v2.to_csv('/content/drive/MyDrive/dados_pedidos/Nets/Ciclo_pedido/pedidos_analise.csv')'''"
      ],
      "metadata": {
        "id": "RsodE3ii-CcM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "05_Ciclo_Pedido_Nets.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}